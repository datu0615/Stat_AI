{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"kobert_mecab3_kfold.ipynb","provenance":[{"file_id":"12hCD7UZ15IxfjW8pNi3uaOq5fGxIxw4X","timestamp":1626014439720},{"file_id":"14qEgegzHqlPAFj8YYtvH79kVzWRSns2Q","timestamp":1625760424590}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ed863819865c4341b0ba285971539386":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3460dbbf9cdf4740b1c7e82ed94e0b94","IPY_MODEL_aa3a72af733c48a780703a85acf84c59","IPY_MODEL_a668c301626c4e8d97ecd544bf94263a"],"layout":"IPY_MODEL_e997a6b066594bf49646ee0a37f53d6b"}},"3460dbbf9cdf4740b1c7e82ed94e0b94":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e69118e138ff4eaab055d0db8df7e58a","placeholder":"​","style":"IPY_MODEL_9ae4f3b73b694d8b99fdb2246da266fd","value":"Downloading: 100%"}},"aa3a72af733c48a780703a85acf84c59":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_efe1ed11492f4d97ae64a9bc6208b937","max":371391,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3ca539ace3ae430ea23cc5015e1d0c03","value":371391}},"a668c301626c4e8d97ecd544bf94263a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_544ecca8792c46deb4fe6779a8ff467a","placeholder":"​","style":"IPY_MODEL_6ca2992d1b9f4abfac950adab8295136","value":" 371k/371k [00:00&lt;00:00, 619kB/s]"}},"e997a6b066594bf49646ee0a37f53d6b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e69118e138ff4eaab055d0db8df7e58a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ae4f3b73b694d8b99fdb2246da266fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"efe1ed11492f4d97ae64a9bc6208b937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3ca539ace3ae430ea23cc5015e1d0c03":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"544ecca8792c46deb4fe6779a8ff467a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ca2992d1b9f4abfac950adab8295136":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd10a186c2df476c84772d255c279d85":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a30416ea3914c48ac2a1f89084388d0","IPY_MODEL_e7b14906fc5d4350925b8dc5074ae93a","IPY_MODEL_9c1608db032c4315ad49114894ca7024"],"layout":"IPY_MODEL_a04aae9e0d7c446594d41edb7e4f7d11"}},"7a30416ea3914c48ac2a1f89084388d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28175c7380b94407b105cfe716038392","placeholder":"​","style":"IPY_MODEL_041f8ea3951d4efb81a4b84386da9461","value":"Downloading: 100%"}},"e7b14906fc5d4350925b8dc5074ae93a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_388579c13c2e40eaad1c51068ba4e743","max":77779,"min":0,"orientation":"horizontal","style":"IPY_MODEL_83b3092e4eeb49e29a49672896da96f7","value":77779}},"9c1608db032c4315ad49114894ca7024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d6b6b2d9e21c40778a0e1e35a7f2afde","placeholder":"​","style":"IPY_MODEL_6b6f98f657db4d1aa190519666778b97","value":" 77.8k/77.8k [00:00&lt;00:00, 313kB/s]"}},"a04aae9e0d7c446594d41edb7e4f7d11":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28175c7380b94407b105cfe716038392":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"041f8ea3951d4efb81a4b84386da9461":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"388579c13c2e40eaad1c51068ba4e743":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"83b3092e4eeb49e29a49672896da96f7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d6b6b2d9e21c40778a0e1e35a7f2afde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b6f98f657db4d1aa190519666778b97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"19b29fb0339e4187b36b8debd6604fcf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b1b2b417c9e34306b94a2597aff66939","IPY_MODEL_3834361476824dc1a9b6826b9387ebeb","IPY_MODEL_77023a8fb29448cd9814d9c145cfa7d6"],"layout":"IPY_MODEL_daf3d4b29e0343159a26879e252ca148"}},"b1b2b417c9e34306b94a2597aff66939":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c6ad64cee46f44f5bc923cff66bb0300","placeholder":"​","style":"IPY_MODEL_5cd16d8f02854419b5527b9dc9d40a9e","value":"Downloading: 100%"}},"3834361476824dc1a9b6826b9387ebeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b27d65a1115490cb8e5f229ba79c486","max":426,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c3bfc9cf222d44409621b5ca6e6510db","value":426}},"77023a8fb29448cd9814d9c145cfa7d6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_727e0433a6a345b1a81568cff4f910c7","placeholder":"​","style":"IPY_MODEL_00462899e0b540d08a71fe46c8920318","value":" 426/426 [00:00&lt;00:00, 16.9kB/s]"}},"daf3d4b29e0343159a26879e252ca148":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6ad64cee46f44f5bc923cff66bb0300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cd16d8f02854419b5527b9dc9d40a9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b27d65a1115490cb8e5f229ba79c486":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3bfc9cf222d44409621b5ca6e6510db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"727e0433a6a345b1a81568cff4f910c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"00462899e0b540d08a71fe46c8920318":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f5645cb67055471294715a47ba80390e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_572c46d818ae42f1805e2427ae501289","IPY_MODEL_b47b6d5991774078b34477378f935823","IPY_MODEL_3ffab7c2a2ff4d4b813507da0aca53db"],"layout":"IPY_MODEL_2d321bb2b39c47b39c154c2836f331a4"}},"572c46d818ae42f1805e2427ae501289":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa925d7709a48c58e4bc01cd0a48ea5","placeholder":"​","style":"IPY_MODEL_397244780fca4147ae13769a3dae7291","value":"Downloading: 100%"}},"b47b6d5991774078b34477378f935823":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24aa2d307a33432282ca5d39397ea8bd","max":368792146,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2b5b9dbb71ce44ce9059e5f698dd570e","value":368792146}},"3ffab7c2a2ff4d4b813507da0aca53db":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9665bfe91cd44e66be3947c2dc5f5950","placeholder":"​","style":"IPY_MODEL_db93db3f8abb4097ba7c6d378eb33b61","value":" 369M/369M [00:05&lt;00:00, 66.1MB/s]"}},"2d321bb2b39c47b39c154c2836f331a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1aa925d7709a48c58e4bc01cd0a48ea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"397244780fca4147ae13769a3dae7291":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24aa2d307a33432282ca5d39397ea8bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b5b9dbb71ce44ce9059e5f698dd570e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9665bfe91cd44e66be3947c2dc5f5950":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db93db3f8abb4097ba7c6d378eb33b61":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","metadata":{"id":"5HAji7s04eRe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668480152,"user_tz":-540,"elapsed":20439,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"82f266d4-8d65-4fe3-fd69-d9db46b3d5df"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"9V1puuSQM_BU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c884a498-f352-4ab6-d1fd-683242847d48","executionInfo":{"status":"ok","timestamp":1649668501198,"user_tz":-540,"elapsed":21050,"user":{"displayName":"장준보","userId":"12796992458142872403"}}},"source":["!pip install hanja\n","!pip install wordcloud\n","!pip install transformers==3.2\n","!pip install tensorflow-addons\n","!pip install konlpy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting hanja\n","  Downloading hanja-0.13.3.tar.gz (120 kB)\n","\u001b[K     |████████████████████████████████| 120 kB 15.2 MB/s \n","\u001b[?25hCollecting pyyaml==5.1.2\n","  Downloading PyYAML-5.1.2.tar.gz (265 kB)\n","\u001b[K     |████████████████████████████████| 265 kB 57.1 MB/s \n","\u001b[?25hRequirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from hanja) (3.6.4)\n","Collecting pytest-cov\n","  Downloading pytest_cov-3.0.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: coveralls in /usr/local/lib/python3.7/dist-packages (from hanja) (0.5)\n","Requirement already satisfied: coverage<3.999,>=3.6 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (3.7.1)\n","Requirement already satisfied: docopt>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (0.6.2)\n","Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from coveralls->hanja) (2.23.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->coveralls->hanja) (2021.10.8)\n","Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.11.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (57.4.0)\n","Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (0.7.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.15.0)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (21.4.0)\n","Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (8.12.0)\n","Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->hanja) (1.4.0)\n","Collecting pytest\n","  Downloading pytest-7.1.1-py3-none-any.whl (297 kB)\n","\u001b[K     |████████████████████████████████| 297 kB 63.7 MB/s \n","\u001b[?25hCollecting coverage[toml]>=5.2.1\n","  Downloading coverage-6.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 97.5 MB/s \n","\u001b[?25h  Downloading coverage-6.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 95.3 MB/s \n","\u001b[?25h  Downloading coverage-6.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207 kB)\n","\u001b[K     |████████████████████████████████| 207 kB 100.0 MB/s \n","\u001b[?25h  Downloading coverage-6.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 100.4 MB/s \n","\u001b[?25h  Downloading coverage-6.1.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 86.6 MB/s \n","\u001b[?25h  Downloading coverage-6.1.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 97.8 MB/s \n","\u001b[?25h  Downloading coverage-6.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (213 kB)\n","\u001b[K     |████████████████████████████████| 213 kB 87.4 MB/s \n","\u001b[?25h  Downloading coverage-6.0.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (253 kB)\n","\u001b[K     |████████████████████████████████| 253 kB 95.1 MB/s \n","\u001b[?25h  Downloading coverage-6.0.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n","\u001b[K     |████████████████████████████████| 252 kB 93.8 MB/s \n","\u001b[?25h  Downloading coverage-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (252 kB)\n","\u001b[K     |████████████████████████████████| 252 kB 76.2 MB/s \n","\u001b[?25h  Downloading coverage-5.5-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 98.0 MB/s \n","\u001b[?25h  Downloading coverage-5.4-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 100.0 MB/s \n","\u001b[?25h  Downloading coverage-5.3.1-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n","\u001b[K     |████████████████████████████████| 242 kB 85.0 MB/s \n","\u001b[?25h  Downloading coverage-5.3-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 97.1 MB/s \n","\u001b[?25h  Downloading coverage-5.2.1-cp37-cp37m-manylinux1_x86_64.whl (229 kB)\n","\u001b[K     |████████████████████████████████| 229 kB 94.7 MB/s \n","\u001b[?25hINFO: pip is looking at multiple versions of pytest-cov to determine which version is compatible with other requirements. This could take a while.\n","Collecting pytest-cov\n","  Downloading pytest_cov-2.12.1-py2.py3-none-any.whl (20 kB)\n","Collecting toml\n","  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n","Collecting pytest-cov\n","  Downloading pytest_cov-2.12.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.1-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.11.0-py2.py3-none-any.whl (20 kB)\n","  Downloading pytest_cov-2.10.1-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.10.0-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.9.0-py2.py3-none-any.whl (19 kB)\n","  Downloading pytest_cov-2.8.1-py2.py3-none-any.whl (18 kB)\n","  Downloading pytest_cov-2.8.0-py2.py3-none-any.whl (18 kB)\n","  Downloading pytest_cov-2.7.1-py2.py3-none-any.whl (17 kB)\n","  Downloading pytest_cov-2.7.0-py2.py3-none-any.whl (17 kB)\n","  Downloading pytest_cov-2.6.1-py2.py3-none-any.whl (16 kB)\n","  Downloading pytest_cov-2.6.0-py2.py3-none-any.whl (14 kB)\n","  Downloading pytest_cov-2.5.1-py2.py3-none-any.whl (21 kB)\n","Building wheels for collected packages: hanja, pyyaml\n","  Building wheel for hanja (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hanja: filename=hanja-0.13.3-py3-none-any.whl size=128426 sha256=a2990ebca7bbfe9d66852d2737f44c57715a864fe42f8d0a8b56379a958ab39b\n","  Stored in directory: /root/.cache/pip/wheels/70/08/88/f9cd32ddb92f5c3061cf16f068c842dc558d2f66a9c943b51a\n","  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyyaml: filename=PyYAML-5.1.2-cp37-cp37m-linux_x86_64.whl size=44118 sha256=72a6607a93cbc3af3065dc4dfbfb09252ef1672591ac9bab8627ef038edcda3f\n","  Stored in directory: /root/.cache/pip/wheels/23/b9/73/57aaccb6957d94ed63f474b51a9f7f992c5eff4635052c0557\n","Successfully built hanja pyyaml\n","Installing collected packages: pyyaml, pytest-cov, hanja\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed hanja-0.13.3 pytest-cov-2.5.1 pyyaml-5.1.2\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (1.5.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud) (7.1.2)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from wordcloud) (1.21.5)\n","Collecting transformers==3.2\n","  Downloading transformers-3.2.0-py3-none-any.whl (1.0 MB)\n","\u001b[K     |████████████████████████████████| 1.0 MB 14.4 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (4.63.0)\n","Collecting tokenizers==0.8.1.rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 52.0 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (3.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (2019.12.20)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 77.8 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.2) (1.21.5)\n","Collecting sentencepiece!=0.1.92\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 80.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.2) (3.0.7)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.2) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.2) (7.1.2)\n","Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n","Successfully installed sacremoses-0.0.49 sentencepiece-0.1.96 tokenizers-0.8.1rc2 transformers-3.2.0\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 13.9 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.16.1\n","Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 14.7 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 92.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n","Installing collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.3.0 konlpy-0.6.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"ntscQjKSowSY"},"source":["# MECAB"]},{"cell_type":"code","metadata":{"id":"YhLqvWQi6dlL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668503320,"user_tz":-540,"elapsed":2130,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"555626cf-5a6b-4ea6-cf3d-4c0373d1fb8f"},"source":["! git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'Mecab-ko-for-Google-Colab'...\n","remote: Enumerating objects: 109, done.\u001b[K\n","remote: Counting objects: 100% (18/18), done.\u001b[K\n","remote: Compressing objects: 100% (14/14), done.\u001b[K\n","remote: Total 109 (delta 7), reused 10 (delta 3), pack-reused 91\u001b[K\n","Receiving objects: 100% (109/109), 1.27 MiB | 1.16 MiB/s, done.\n","Resolving deltas: 100% (46/46), done.\n"]}]},{"cell_type":"code","metadata":{"id":"j-953ZZ8_nMz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668503321,"user_tz":-540,"elapsed":8,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"8ac86b33-22a7-4c81-8892-ad4142302754"},"source":["cd Mecab-ko-for-Google-Colab"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/Mecab-ko-for-Google-Colab\n"]}]},{"cell_type":"code","metadata":{"id":"RuLVd0p__pjb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668800810,"user_tz":-540,"elapsed":297495,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"7544c73d-a1cc-4dc3-c424-365b80f3d0cb"},"source":["! bash install_mecab-ko_on_colab190912.sh"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Installing konlpy.....\n","Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.6.0)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.10.0.2)\n","Done\n","Installing mecab-0.996-ko-0.9.2.tar.gz.....\n","Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","--2022-04-11 09:15:05--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22cd:e0db, 2406:da00:ff00::22e9:9f55, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=TWdcSzdsjJFdS5CSSxy06%2B%2FU074%3D&Expires=1649670126&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n","--2022-04-11 09:15:05--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=TWdcSzdsjJFdS5CSSxy06%2B%2FU074%3D&Expires=1649670126&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.45.108\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.45.108|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1414979 (1.3M) [application/x-tar]\n","Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n","\n","mecab-0.996-ko-0.9. 100%[===================>]   1.35M  2.69MB/s    in 0.5s    \n","\n","2022-04-11 09:15:06 (2.69 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n","\n","Done\n","Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n","Done\n","Change Directory to mecab-0.996-ko-0.9.2.......\n","installing mecab-0.996-ko-0.9.2.tar.gz........\n","configure\n","make\n","make check\n","make install\n","ldconfig\n","Done\n","Change Directory to /content\n","Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","--2022-04-11 09:16:22--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n","Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c5:2ef4, 2406:da00:ff00::22e9:9f55, ...\n","Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=YSvYGP10d4d5331BCOfhDAAI0xU%3D&Expires=1649669857&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n","--2022-04-11 09:16:23--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=YSvYGP10d4d5331BCOfhDAAI0xU%3D&Expires=1649669857&AWSAccessKeyId=AKIA6KOSE3BNA7WTAGHW&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n","Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 54.231.136.169\n","Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|54.231.136.169|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49775061 (47M) [application/x-tar]\n","Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n","\n","mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  24.4MB/s    in 1.9s    \n","\n","2022-04-11 09:16:25 (24.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n","\n","Done\n","Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n","Done\n","Change Directory to mecab-ko-dic-2.1.1-20180720\n","Done\n","installing........\n","configure\n","make\n","make install\n","apt-get update\n","apt-get upgrade\n","apt install curl\n","apt install git\n","bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n","Done\n","Successfully Installed\n","Now you can use Mecab\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n","NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n","블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"]}]},{"cell_type":"markdown","metadata":{"id":"_Jlv7vxarCB4"},"source":["# IMPORT"]},{"cell_type":"code","metadata":{"id":"BzxIbpTpvr6G"},"source":["import numpy as np\n","import pandas as pd\n","import os\n","import re\n","import json\n","import matplotlib.pyplot as plt\n","%matplotlib inline \n","from wordcloud import WordCloud\n","import seaborn as sns\n","from tqdm import tqdm\n","\n","import hanja\n","from hanja import hangul\n","from konlpy.tag import Mecab\n","mecab = Mecab()\n","\n","from transformers import *\n","\n","import tensorflow as tf\n","import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","from sklearn.metrics import accuracy_score, log_loss\n","from sklearn.model_selection import train_test_split, KFold, cross_val_score, StratifiedKFold\n","from tensorflow.keras.models import clone_model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ls5o_-bCEsYE"},"source":["https://github.com/monologg/KoBERT-Transformers 참고하였습니다."]},{"cell_type":"code","metadata":{"id":"3AmgkdPb482G"},"source":["import logging\n","import os\n","import unicodedata\n","from shutil import copyfile\n"," \n","from transformers import PreTrainedTokenizer\n"," \n"," \n","logger = logging.getLogger(__name__)\n"," \n","VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n","                     \"vocab_txt\": \"vocab.txt\"}\n"," \n","PRETRAINED_VOCAB_FILES_MAP = {\n","    \"vocab_file\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n","    },\n","    \"vocab_txt\": {\n","        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n","        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n","        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n","    }\n","}\n"," \n","PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n","    \"monologg/kobert\": 512,\n","    \"monologg/kobert-lm\": 512,\n","    \"monologg/distilkobert\": 512\n","}\n"," \n","PRETRAINED_INIT_CONFIGURATION = {\n","    \"monologg/kobert\": {\"do_lower_case\": False},\n","    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n","    \"monologg/distilkobert\": {\"do_lower_case\": False}\n","}\n"," \n","SPIECE_UNDERLINE = u'▁'\n"," \n"," \n","class KoBertTokenizer(PreTrainedTokenizer):\n","    \"\"\"\n","        SentencePiece based tokenizer. Peculiarities:\n","            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n","    \"\"\"\n","    vocab_files_names = VOCAB_FILES_NAMES\n","    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n","    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n","    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n"," \n","    def __init__(\n","            self,\n","            vocab_file,\n","            vocab_txt,\n","            do_lower_case=False,\n","            remove_space=True,\n","            keep_accents=False,\n","            unk_token=\"[UNK]\",\n","            sep_token=\"[SEP]\",\n","            pad_token=\"[PAD]\",\n","            cls_token=\"[CLS]\",\n","            mask_token=\"[MASK]\",\n","            **kwargs):\n","        super().__init__(\n","            unk_token=unk_token,\n","            sep_token=sep_token,\n","            pad_token=pad_token,\n","            cls_token=cls_token,\n","            mask_token=mask_token,\n","            **kwargs\n","        )\n"," \n","        # Build vocab\n","        self.token2idx = dict()\n","        self.idx2token = []\n","        with open(vocab_txt, 'r', encoding='utf-8') as f:\n","            for idx, token in enumerate(f):\n","                token = token.strip()\n","                self.token2idx[token] = idx\n","                self.idx2token.append(token)\n"," \n","        self.max_len_single_sentence = self.max_len - 2  \n","        self.max_len_sentences_pair = self.max_len - 3  \n"," \n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n"," \n","        self.do_lower_case = do_lower_case\n","        self.remove_space = remove_space\n","        self.keep_accents = keep_accents\n","        self.vocab_file = vocab_file\n","        self.vocab_txt = vocab_txt\n"," \n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(vocab_file)\n"," \n","    @property\n","    def vocab_size(self):\n","        return len(self.idx2token)\n"," \n","    def __getstate__(self):\n","        state = self.__dict__.copy()\n","        state[\"sp_model\"] = None\n","        return state\n"," \n","    def __setstate__(self, d):\n","        self.__dict__ = d\n","        try:\n","            import sentencepiece as spm\n","        except ImportError:\n","            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n","                           \"pip install sentencepiece\")\n","        self.sp_model = spm.SentencePieceProcessor()\n","        self.sp_model.Load(self.vocab_file)\n"," \n","    def preprocess_text(self, inputs):\n","        if self.remove_space:\n","            outputs = \" \".join(inputs.strip().split())\n","        else:\n","            outputs = inputs\n","        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n"," \n","        if not self.keep_accents:\n","            outputs = unicodedata.normalize('NFKD', outputs)\n","            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n","        if self.do_lower_case:\n","            outputs = outputs.lower()\n"," \n","        return outputs\n"," \n","    def _tokenize(self, text, return_unicode=True, sample=False):\n","        \"\"\" Tokenize a string. \"\"\"\n","        text = self.preprocess_text(text)\n"," \n","        if not sample:\n","            pieces = self.sp_model.EncodeAsPieces(text)\n","        else:\n","            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n","        new_pieces = []\n","        for piece in pieces:\n","            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n","                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n","                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n","                    if len(cur_pieces[0]) == 1:\n","                        cur_pieces = cur_pieces[1:]\n","                    else:\n","                        cur_pieces[0] = cur_pieces[0][1:]\n","                cur_pieces.append(piece[-1])\n","                new_pieces.extend(cur_pieces)\n","            else:\n","                new_pieces.append(piece)\n"," \n","        return new_pieces\n"," \n","    def _convert_token_to_id(self, token):\n","        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n","        return self.token2idx.get(token, self.token2idx[self.unk_token])\n"," \n","    def _convert_id_to_token(self, index, return_unicode=True):\n","        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n","        return self.idx2token[index]\n"," \n","    def convert_tokens_to_string(self, tokens):\n","        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n","        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n","        return out_string\n"," \n","    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n","        by concatenating and adding special tokens.\n","        A RoBERTa sequence has the following format:\n","            single sequence: [CLS] X [SEP]\n","            pair of sequences: [CLS] A [SEP] B [SEP]\n","        \"\"\"\n","        if token_ids_1 is None:\n","            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        sep = [self.sep_token_id]\n","        return cls + token_ids_0 + sep + token_ids_1 + sep\n"," \n","    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n","        \"\"\"\n","        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n","        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n","        Args:\n","            token_ids_0: list of ids (must not contain special tokens)\n","            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n","                for sequence pairs\n","            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n","                special tokens for the model\n","        Returns:\n","            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n","        \"\"\"\n"," \n","        if already_has_special_tokens:\n","            if token_ids_1 is not None:\n","                raise ValueError(\n","                    \"You should not supply a second sequence if the provided sequence of \"\n","                    \"ids is already formated with special tokens for the model.\"\n","                )\n","            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n"," \n","        if token_ids_1 is not None:\n","            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n","        return [1] + ([0] * len(token_ids_0)) + [1]\n"," \n","    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n","        \"\"\"\n","        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n","        A BERT sequence pair mask has the following format:\n","        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n","        | first sequence    | second sequence\n","        if token_ids_1 is None, only returns the first portion of the mask (0's).\n","        \"\"\"\n","        sep = [self.sep_token_id]\n","        cls = [self.cls_token_id]\n","        if token_ids_1 is None:\n","            return len(cls + token_ids_0 + sep) * [0]\n","        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n"," \n","    def save_vocabulary(self, save_directory):\n","        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n","            to a directory.\n","        \"\"\"\n","        if not os.path.isdir(save_directory):\n","            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n","            return\n"," \n","        # 1. Save sentencepiece model\n","        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n"," \n","        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n","            copyfile(self.vocab_file, out_vocab_model)\n"," \n","        # 2. Save vocab.txt\n","        index = 0\n","        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n","        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n","            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n","                if index != token_index:\n","                    logger.warning(\n","                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n","                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n","                    )\n","                    index = token_index\n","                writer.write(token + \"\\n\")\n","                index += 1\n"," \n","        return out_vocab_model, out_vocab_txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2iXF8Qcru5VX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668814754,"user_tz":-540,"elapsed":4773,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"3130971a-d39c-499f-fab4-c94d1ba38ab8"},"source":["PATH = '/content/drive/MyDrive/stat/'\n","\n","\n","train = pd.read_csv(PATH + \"train_all_clean2.csv\", error_bad_lines=False)\n","test = pd.read_csv(PATH + \"test_all_clean2.csv\",error_bad_lines=False)\n","\n","# train['digit_1'] = train['digit_1'].astype('str')\n","# train['digit_2'] = train['digit_2'].astype('str')\n","# train['digit_3'] = train['digit_3'].astype('str')\n","\n","# train['text_all'] = train['text_obj'].map(str)+\" \"+train['text_mthd'].map(str)+\" \"+train['text_deal'].map(str)\n","# test['text_all'] = test['text_obj'].map(str)+\" \"+test['text_mthd'].map(str)+\" \"+test['text_deal'].map(str)\n","\n","from sklearn.preprocessing import LabelEncoder\n","\n","le1 = LabelEncoder()\n","le1 = le1.fit(train['digit_1'])  \n","train['digit_1'] = le1.transform(train['digit_1'])  \n","\n","le2 = LabelEncoder()\n","le2 = le2.fit(train['digit_2'])  \n","train['digit_2'] = le2.transform(train['digit_2'])  \n","\n","le3 = LabelEncoder()\n","le3 = le3.fit(train['digit_3'])  \n","train['digit_3'] = le3.transform(train['digit_3'])  \n","\n","STOPWORDSPATH =\"/content/drive/MyDrive/stat/stopwords.txt\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version.\n","\n","\n","  exec(code_obj, self.user_global_ns, self.user_ns)\n"]}]},{"cell_type":"code","source":["# 문장 길이 분포도 확인\n","train['doc_len'] = train.text_sum.apply(lambda words: len(words.split()))\n","\n","def plot_doc_lengths(dataframe):\n","    mean_seq_len = np.round(dataframe.doc_len.mean()).astype(int)\n","    sns.distplot(tuple(dataframe.doc_len), hist=True, kde=True, label='Document lengths')\n","    plt.axvline(x=mean_seq_len, color='k', linestyle='--', label=f'Sequence length mean:{mean_seq_len}')\n","    plt.title('Document lengths')\n","    plt.legend()\n","    plt.show()\n","    print(f\" 가장 긴 문장은 {train['doc_len'].max()} 개의 단어를, 가장 짧은 문장은 {train['doc_len'].min()} 개의 단어를 가지고 있습니다.\")\n","\n","plot_doc_lengths(train)"],"metadata":{"id":"Xx22-yI2-ymy","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"ok","timestamp":1649668819329,"user_tz":-540,"elapsed":4579,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"f2352248-8c32-43f9-db45-3c819bd887bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n","  warnings.warn(msg, FutureWarning)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2dd5xcZbn4v8+ULUk2dTcE0kMJpAMhAVEpEohIEX6AAiJNuJTQVBABIYJ4ucjFgqCiIooiJSBGyhWCoQRCwiYEUkhCypJsSNndtO075f39ccrO7J6ZORsy2Z3Z5+sn7plz3nPOe3aW9zlPF2MMiqIoSvcl0NkTUBRFUToXFQSKoijdHBUEiqIo3RwVBIqiKN0cFQSKoijdHBUEiqIo3RwVBIrSSYhIhYic1An3HSEiRkRC+/reStdEBYGyz7EXwEYRqRWRnSLyrohcJSJ58/coIjNF5K+dPQ/oPIGj5A558x+eknOcbowpAYYD9wE/AP7YuVNSlO6JCgKlUzHG7DLGzAa+AVwsIuMARKSPiPxFRKpE5FMRuSNRYxCRK0TkY1urWCEiR9j7jYgclDDucRH5ib19vIhUisgtIrJNRDaLyNdF5FQRWS0i20XktoRzAyJyq4isFZEaEXlGRPrbxxzzysUiskFEqkXkdvvYdOA24BsiUiciH2b6PezpvezjxSLyZxHZYf9ObhGRSvvYE8Aw4F/2XG5JuO2FKa43RUTKRWS3iGwVkQd9f6FKTqKCQOkSGGMWApXAl+xdDwF9gFHAccC3gUsBRORcYKa9rzdwBlDj81aDgCJgMHAn8HvgW8CR9r1/JCIj7bHXAV+3738AsAN4uM31vgiMBr4C3Ckihxlj/g/4KfC0MaaXMWaij3nt0b3s/XcBI7B+V9Ps5wHAGHMRsAFLA+tljLnfx/V+CfzSGNMbOBB4xsf8lRxGBYHSlfgM6C8iQeCbwA+NMbXGmArgf4GL7HHfAe43xrxvLNYYYz71eY8IcK8xJgI8BZRiLXq1xpjlwArAWbivAm43xlQaY5qxhM85bZysPzbGNBpjPgQ+TDi3o3yee50H/NQYs8MYUwn8yuc9U10vAhwkIqXGmDpjzHt7+ExKjqCCQOlKDAa2Yy3OYSBxcf/UPg4wFFi7h/eoMcbE7O1G++fWhOONQC97ezjwD9uhvRP4GIgB+yWM35Kw3ZBwbkf5PPc6ANiYcCxxOx2prnc5cAiwUkTeF5HTfF5PyVFUEChdAhE5CmuhnwdUY72VDk8YMgzYZG9vxDJZeNEA9Ej4POhzTGsj8FVjTN+Ef0XGmE0Zz4SOlvX9PPfaDAxJ+Dz088zFGPOJMeZ8YCDwP8AsEenZkWsouYUKAqVTEZHe9hvnU8BfjTFL7Tf2Z4B7RaRERIYD3wWccMw/AN8XkSPF4iB7DMAS4AIRCdpO2+M+x/R+a89huD3XMhE50+e5W4ERHQiJ/Tz3egb4oYj0E5HBwAyPuYzyeS1E5FsiUmaMiQM77d1xv+cruYcKAqWz+JeI1GK9Cd8OPIjtDLa5DqgH1mFpCU8CjwEYY54F7rX31QIvAP3t824ATsdawC60j+0pvwRmA6/ac30PmOrz3GftnzUisjjL97oby9G+HpgDzAKaE47/N3CHbXb6vo/rTQeWi0idPa9vGmMaM5yj5DCijWkUJb8QkauxFu/Pow0p3QjVCBQlxxGR/UXkWDsXYTTwPeAfnT0vJXfQWiOKkvsUAL8DRmKZxJ4CHunUGSk5hZqGFEVRujlqGlIURenm5JxpqLS01IwYMaKzp5GzrFq1CoDRo0d38kwURdmXLFq0qNoYU+Z1LOcEwYgRIygvL+/saeQsxx9/PABvvPFGp85DUZR9i4ikLMOipiFFUZRuTs5pBMrn44477ujsKSiK0sVQQdDNOOkkbVSlKEoyKgi6GUuWLAFg0qRJnTyT/CUSiVBZWUlTU1NnT0XphhQVFTFkyBDC4bDvc1QQdDNuvPFGQJ3F2aSyspKSkhJGjBiBiHT2dJRuhDGGmpoaKisrGTlyZOYTbLLmLBaRx+x2gMtSHBcR+ZWIrBGRj5xWg4qS6zQ1NTFgwAAVAso+R0QYMGBAh7XRbEYNPY5VxTAVXwUOtv9dCfwmi3NRlH2KCgGls9iTv72sCQJjzFtY3aZScSbwF7vV4HtAXxHZP1vzURRFUbzpzDyCwSS31KuktRVhEiJypYiUi0h5VVXVPplcvrJhewNrttV19jSULHLvvfcyduxYJkyYwKRJk1iwYEFnT+lzcckllzBr1qy9ft2f/vSn7nZFRQXjxo3b6/fY2+zcuZNzzjmHQw89lMMOO4z58+fvlevmhLPYGPMo8CjA5MmTtUre5+Cw06+kuq6ls6ehZIn58+fz4osvsnjxYgoLC6murqalRb9vL376059y2223dfY0OsQNN9zA9OnTmTVrFi0tLTQ0NOyV63amRrCJ5N6qQ2jtSatkif6jxlMyfGxnT0PJEps3b6a0tJTCwkIASktLOeCAAwBYtGgRxx13HEceeSSnnHIKmzdvdvdPnDiRiRMncvPNN7tvxo8//jgzZrR2vTzttNPcaLNXX32VY445hiOOOIJzzz2XujpLyxwxYgR33XUXRxxxBOPHj2flypUA1NXVcemllzJ+/HgmTJjAc889l/Y6qUj1DMcffzw/+MEPmDJlCocccghvv/02AA0NDZx33nmMGTOGs846i6lTp1JeXs6tt95KY2MjkyZN4sILLwQgFotxxRVXMHbsWE4++WQaG9s3Zbvkkku4+uqrOfrooxk1ahRvvPEGl112GYcddhiXXHKJOy7Vc919990cddRRjBs3jiuvvBKn+nOq+Seya9cu3nrrLS6//HIACgoK6Nu3b9rfl186UxDMBr5tRw8dDewyxmzuxPl0C7Z+8iE1az/q7Gl0K44//vh2/x55xGoX0NDQ4Hn88ccfB6C6urrdsXScfPLJbNy4kUMOOYRrrrmGN998E7ByG6677jpmzZrFokWLuOyyy7j99tsBuPTSS3nooYf48MMPfT1PdXU1P/nJT5gzZw6LFy9m8uTJPPjgg+7x0tJSFi9ezNVXX80DDzwAwD333EOfPn1YunQpH330ESeeeGLG67Ql3TMARKNRFi5cyC9+8Qt+/OMfA/DII4/Qr18/VqxYwT333MOiRYsAuO+++yguLmbJkiX87W9/A+CTTz7h2muvZfny5fTt29cVVm3ZsWMH8+fP5+c//zlnnHEGN910E8uXL2fp0qUsWbIk7XPNmDGD999/n2XLltHY2MiLL76Ydv6fffYZp556KgDr16+nrKyMSy+9lMMPP5zvfOc71NfX+/rOMpE105CI/B04HigVkUrgLiAMYIz5LfAycCqwBmgguV+tkiWWPP9bmqNxrJbASr7Rq1cvFi1axNtvv83cuXP5xje+wX333cfkyZNZtmwZ06ZNA6y33/3335+dO3eyc+dOvvzlLwNw0UUX8corr6S9x3vvvceKFSs49thjAWhpaeGYY45xj5999tkAHHnkkTz//PMAzJkzh6eeesod069fP1588cW012nLqlWrPJ/B674VFRUAzJs3jxtuuAGAcePGMWHChJTXHzlypJtomXiNtpx++umICOPHj2e//fZj/PjxAIwdO5aKigoqKytTPtfcuXO5//77aWhoYPv27YwdO5bTTz895fwPOOAAXn75ZcASFIsXL+ahhx5i6tSp3HDDDdx3333cc889KZ/JL1kTBMaY8zMcN8C12bq/4o0BDOpm2ZekS97r0aNH2uOlpaUdTv4LBoOu9jB+/Hj+/Oc/c+SRRzJ27Nh2zsWdO3emvE4oFCIej7ufndh0YwzTpk3j73//u+d5jlkqGAwSjUZTXj/TdbzGez1DR++bCud85xpepqHEcYFAIOmcQCBANBolGAx6PldTUxPXXHMN5eXlDB06lJkzZybF+2ea/5AhQxgyZAhTp04F4JxzzuG+++7r8HN6odVHuxnGGLQpXf6yatUqPvnkE/fzkiVLGD58OKNHj6aqqspdRCORiGsC6du3L/PmzQNwzSRg2fuXLFlCPB5n48aNLFy4EICjjz6ad955hzVr1gBQX1/P6tWr085r2rRpPPzww+7nHTt2dPg6qZ4hHcceeyzPPPMMACtWrGDp0qXusXA4TCQSSXv+npDquZxFv7S0lLq6ug5HQg0aNIihQ4e6PUVef/11xowZs1fmrIKgm2Hsf0p+UldXx8UXX8yYMWOYMGECK1asYObMmRQUFDBr1ix+8IMfMHHiRCZNmsS7774LwJ/+9CeuvfZaJk2aRGLr2mOPPZaRI0cyZswYrr/+eo44wkr+Lysr4/HHH+f8889nwoQJHHPMMa5TOBV33HEHO3bsYNy4cUycOJG5c+d2+DrpniEV11xzDVVVVYwZM4Y77riDsWPH0qdPHwCuvPJKJkyY4DqL9xapnqtv375cccUVjBs3jlNOOYWjjjoq47USfQQADz30EBdeeCETJkxgyZIley3qKed6Fk+ePNloY5o9p/9Bh9McjVFfoQ7jbPHxxx9z2GGHdfY09oiKigpOO+00li3zrAyTc8RiMSKRCEVFRaxdu5aTTjqJVatWUVBQ0NlTyypef4MissgYM9lrfE7kESh7j9Ffv5Ytu5o7exqKsk9oaGjghBNOIBKJYIzhkUceyXshsCeoIMhxHn9nPROG9uWIYf18jS/e/yDChd5OMEUZMWJE3mgDACUlJdra1gfqI8hx/ve11fxjsf88vOpV5dSuW5zFGSmKkmuoRpDjxOKGaNy/n+fTOX+lORojHr+NQEArZCqKohpBzhONG2IJsd6ZcHIIOiI8FEXJb1QQ5DjRWLxDi7oTJBZTQaAoio2ahnKYeNwQN3u2qEficYoJZmFWSlueXLBhr17vgqnD0h4PBoOMHz+eSCRCKBTi29/+NjfddBOBQNd/71uyZEm72HmHN954gwceeCCpPs/e4IUXXuCQQw5xk7OOP/54HnjgASZP9oy0zEu6/l+GkhJHE+iYRmCNjcVUI8hXnGJqy5cv57XXXuOVV15xi5h1dZYsWeLW1tlXvPDCC6xYsWKf3rOroYIgh3E0gY4s6oNOvZ4Bp8xQH0E3YeDAgTz66KP8+te/xhhDU1OTWw768MMPZ+7cuYCVePX973/fLcz20EMPAVY4aXV1NQDl5eVu9dOZM2dy8cUX86UvfYnhw4fz/PPPc8sttzB+/HimT5/ulm7oSNnolpYW7rzzTp5++mkmTZrE008/nfK56uvrueyyy5gyZQqHH344//znPwGrdPbZZ5/N9OnTOfjgg7nlllvcc/74xz9yyCGHMGXKFK644gpmzJjBu+++y+zZs7n55puZNGkSa9euBeDZZ59tVxJ6+fLlTJkyhUmTJjFhwoSkUh65jpqGcpio7STuyKIe7D+YcDTunqvkP6NGjSIWi7Ft2zb++te/IiIsXbqUlStXcvLJJ7N69Wr+9Kc/UVFRwZIlSwiFQmzfnq7LrMXatWuZO3cuK1as4JhjjuG5557j/vvv56yzzuKll17ia1/7Gtdddx3//Oc/KSsr4+mnn+b222/nscceA1rLLr/88sv8+Mc/Zs6cOdx9992Ul5fz61//Ou297733Xk488UQee+wxdu7cyZQpUzjppJMAS6v44IMPKCwsZPTo0Vx33XUEg0HuueceFi9eTElJCSeeeCITJ07kC1/4AmeccQannXYa55xzjnt9r7n99re/5YYbbuDCCy+kpaWFWCz2Ob6VroUKghwmamsCHYka2r3qPWLGEI2dkK1pKV2YefPmcd11VgnyQw89lOHDh7N69WrmzJnDVVddRShkLQn9+/fPeK2vfvWrhMNhxo8fTywWY/r06QCMHz+eioqKPSob7ZdXX32V2bNnu/0Ompqa2LDB8sV85StfcesJjRkzhk8//ZTq6mqOO+4497nOPffctAXuvOZ2zDHHcO+991JZWcnZZ5/NwQcf3KE5d2VUEOQwHfURGGPYscCqDx+L/yBr81K6FuvWrSMYDDJw4MAOn5tYijqxZDIkl2MOh8OIiPs5Go1mtWy0MYbnnnuO0aNHJ+1fsGBBu3LSn6ckdeL5F1xwAVOnTuWll17i1FNP5Xe/+x0nnnhih6/dFVEfQQ7j+AiiPn0EifJCTUPdg6qqKq666ipmzJiBiPClL33JLTW9evVqNmzYwOjRo5k2bRq/+93v3EXPMQ2NGDHC7eqVqmNXKvakbHRJSQm1tbUZr33KKafw0EMPucEPH3zwQdrxRx11FG+++SY7duwgGo0mPYvfe65bt45Ro0Zx/fXXc+aZZ/LRR/lTuFE1ghwmErMWc7/ho4mLvzqL9x2Zwj33Nk4vXid89KKLLuK73/0uYJVlvvrqqxk/fjyhUIjHH3+cwsJCvvOd77B69WomTJhAOBx2nal33XUXl19+OT/60Y8ytslsi1M2+vrrr2fXrl1Eo1FuvPFGxo5N3TP7hBNO4L777mPSpEn88Ic/5Bvf+IbnuB/96EfceOONTJgwgXg8zsiRI9OGlQ4ePJjbbruNKVOm0L9/fw499FDXfPTNb36TK664gl/96ldpewQ888wzPPHEE4TDYQYNGpRzje/ToWWoc5iK6nqOf+ANjhjWl+evOTbj+IaWKP0POhyA8vnzGDe4T7an2C3J5TLU+UxdXR29evUiGo1y1llncdlll3HWWWd19rSyQkfLUKtpKIdx3vD9awTGc1tRugMzZ85k0qRJjBs3jpEjR/L1r3+9s6fUZVDTUA7TUWdxLGYoPe171rb6CJRuhhNhpLRHBUEO0xo+6l8jCPUuSzpXyQ7GGDeKRlH2JXti7ldBkMM4moDjNM5E3BjqP37LPndq1ubV3SkqKqKmpoYBAwaoMFD2KcYYampqKCoq6tB5KghymNge+AhqP3jZ3v5+1ubV3RkyZAiVlZVUVVV19lSUbkhRURFDhgzp0DkqCHKYSKzjPgJ3W30EWSMcDjNy5MjOnoai+EajhnIYt+jcHuQRRNRHoCiKjQqCHKbDUUNx47mtKEr3RgVBDhPtcGax5hEoitIe9RHkMK5G4DNqKBY3lH39hx06R1GU/EcFQQ7TcR+BIdijj7utKIoCKghyGid/IOLbRxCnbukca/vs8Vmbl6IouYUKghymwxpBzLiCIBq/MWvzUhQlt1BncQ6TWGLCT1p5osBQH4GiKA5ZFQQiMl1EVonIGhG51eP4MBGZKyIfiMhHInJqNueTb0Q7GA4aMxo+qihKe7ImCEQkCDwMfBUYA5wvImPaDLsDeMYYczjwTeCRbM0nH4l1sNGMho8qiuJFNjWCKcAaY8w6Y0wL8BRwZpsxBuhtb/cBPsvifPKOSKyDGkFMTUOKorQnm87iwcDGhM+VQNuSlzOBV0XkOqAncJLXhUTkSuBKgGHD9m3bv65MrINv+NG4YeC5M32PVxSle9DZzuLzgceNMUOAU4EnRKTdnIwxjxpjJhtjJpeVle3zSXZVIommIR9v+LG4IRAuIhAuUh+Boigu2RQEm4ChCZ+H2PsSuRx4BsAYMx8oAkqzOKe8ItZB01A0Hqd28UvULn5Ji84piuKSTUHwPnCwiIwUkQIsZ/DsNmM2AF8BEJHDsASBFnH3SUedv7G4oX7l29SvfFvLUCuK4pI1QWCMiQIzgH8DH2NFBy0XkbtF5Ax72PeAK0TkQ+DvwCVmT/qsdVMSy0r70wg0akhRlPZkNbPYGPMy8HKbfXcmbK8Ajs3mHPKZPdEI3PFqGlIUxaazncXK56CjHcdUI1AUxQsVBDlMhzUCO7IoIKI+AkVRXLToXA4TTQof9ecjGHTBffQpDqtpSFEUF9UIcpjExdyPRhC3/fCFoYCahhRFcVGNIIdJLjrnz0ewa8HzSI8wsRFXZnNqiqLkECoIcpiORgHFYobGtQuhIEgk9p1sTk1RlBxCTUM5TCS2Z3kElrNYTUOKolioIMhhOlp0LhY3iAjic7yiKN0DFQQ5TEfLUEfjBgFEJCniSFGU7o36CHKYWDyOCBjjVyOIEwgXEioIafiooiguKghymGjcUBQK0hiJ+SpDHY0bRl74EyYM7UNzRDUCRVEs1DSUw0RjhsKw9RX69REEg0IoECCiPgJFUWxUEOQwMVsjcLYzEY0bqt78G8tefExLTCiK4qKCIIeJxuMd0whihtr1S9j88fvqI1AUxUUFQQ4TTdII/PkIxP6fho8qiuKggiCHicYMRR3QCOLGIAIi/kxJiqJ0D1QQ5DDReJzCDvoIBOyEMvURKIpioeGjOUw0nhA15KfWUDxOuGcfirUMtaIoCaggyGFiceNqBH7e8KMxwxGX3cPhw/ox5+Ot2Z6eoig5gpqGcpg9ySMIBYVQQIvOKYrSimoEOUw0Hm+NGvLZoWzVvx5lZ+9CIuPOzfb0FEXJEVQjyGH2RCPYWbGcTas+Uo1AURQXFQQ5TDRuKAgGCPo09UTjcbv6qJahVhSlFRUEOUwsbggGhGDAX4JYLG5A7PBRH0XqFEXpHqggyGEisTihgOP89ZtZbPUjiBuIq1agKArqLM5pnCigYECSmtSkG9+r/37061lAFRAzhgCS/YkqitKlUY0gRzHGEI0bgoGA73DQWNxwwlV3c9kdDwL+ktAURcl/VBDkKM7CHw4IwUDAfz+CgBAOWlqAlplQFAXUNJSzOAt/MNgxH8F7f3uQdb0LYdQ5GkKqKAqggiBncQRBKCCEgv6jhmo2rKalKASj8OVXUBQl/1HTUI7iZBKHOuAjaM0jsExDqhEoigIqCHIWx77vRA357VDm5BEkXkNRlO6NCoIcxfURBKxm9H5rDYkItkKgGoGiKECWBYGITBeRVSKyRkRuTTHmPBFZISLLReTJbM4nn4i6UUMBWyPI/HYfixsGHDCcA4aPAtRHoCiKRdacxSISBB4GpgGVwPsiMtsYsyJhzMHAD4FjjTE7RGRgtuaTbzglIoIdcBZH44avXzuTqaMGcM3fFqtGoCgKkF2NYAqwxhizzhjTAjwFnNlmzBXAw8aYHQDGmG1ZnE9e4UYN2T4CvwllQVuDsK6hPgJFUXwKAhF5XkS+JiIdERyDgY0JnyvtfYkcAhwiIu+IyHsiMj3F/a8UkXIRKa+qqurAFPKXWLw1aigcCPjKEo7G4/zr4Zn86sc3W5/VNKQoCv41gkeAC4BPROQ+ERm9l+4fAg4GjgfOB34vIn3bDjLGPGqMmWyMmVxWVraXbp3bRBJMQx3RCGo+q2DTp+sALUWtKIqFL0FgjJljjLkQOAKoAOaIyLsicqmIhFOctgkYmvB5iL0vkUpgtjEmYoxZD6zGEgxKBtwSE0HHR+DPWSwJ4aPqI1AUBTrgIxCRAcAlwHeAD4BfYgmG11Kc8j5wsIiMFJEC4JvA7DZjXsDSBhCRUixT0Tr/0+++JIaP+tEI4nGD1Y6gNXxUexIoigI+o4ZE5B/AaOAJ4HRjzGb70NMiUu51jjEmKiIzgH8DQeAxY8xyEbkbKDfGzLaPnSwiK4AYcLMxpubzPVL3INomszhTKGjMWMfrW6LE7e3XVmyloqaBC6YOy+5kFUXp0vgNH/29MeblxB0iUmiMaTbGTE51kn3Oy2323ZmwbYDv2v+UDtA2sziTRuAcLx02mj7FISrBFQiKonRv/JqGfuKxb/7enIjSMVo1AiuzOJOPwDElffGi73Hm1bcDoJYhRVEgg0YgIoOwQj6LReRwWv2MvYEeWZ6bkgY3fDQYIBT0oRHYgiMgQtB2EqhGoCgKZDYNnYLlIB4CPJiwvxa4LUtzUnyQWIbaT9E5R2OY85s7WFAYgqP+y/UbKIrSvUkrCIwxfwb+LCL/zxjz3D6ak+KDpBITHfAR1G/fRjwcBKx2l4qiKJlMQ98yxvwVGCEi7Ry6xpgHPU5T9gGOBvDvZVtYX91AXVOUJxdsAPCMAnLGi/t/oBUmFEWBzKahnvbPXtmeiNIxnDf8QEAICBnNPK7GkJBQpj4CRVEgs2nod/bPH++b6Sh+cUtMiBAISMZF3cuHoD4CRVHAf9G5+0Wkt4iEReR1EakSkW9le3JKahI1gqBIRjOP09x+8OiJHDjuCAC0woSiKOA/j+BkY8xu4DSsWkMHATdna1JKZiKOIBArJDSTRuDkDJzwrRs5579uAayyE4qiKH4FgWNC+hrwrDFmV5bmo/gklmQaymzvd8JHg2IJD1AfgaIoFn5LTLwoIiuBRuBqESkDmrI3LSUT0SRnsRA3VjioOBXl2uCYkp67/7v0LAzB0TPUNKQoCuBTEBhjbhWR+4FdxpiYiNTTvtuYsg9xBYFYggAsm3/QWw644xtrd0Jz0B6vkkBRlI71LD4UK58g8Zy/7OX5KD5pdRa3Lv5xYwjiLQmc2kSJGoP6CBRFAf9lqJ8ADgSWYJWLBjCoIOg0nPDRgB0+CvbCHvQen1iUThAE1QgURbHwqxFMBsYYrUnQZYjFDUJ701C68YDblMbKPcjyJBVFyQn8CoJlwCBgc6aByr4hGjeuJuD8TJcg5vgIDpp4NH16hFkiahpSFMXCryAoBVaIyEKg2dlpjDkjK7NSMhKNxd0wUDccNM3C7vgIpl14LYP7FfPRv5araUhRFMC/IJiZzUkoHScaNwRtCeCnv4CTWRywM0cCImTobgnASx9tZua/lvPOD06kIOS7xbWiKDmE3/DRN0VkOHCwMWaOiPQgpVtS2RfE4sb1DfjxETimoT/cfgUFoQCBk3/oSyNYX11HVW0zdc1R+ocKPv/EFUXpcvitNXQFMAv4nb1rMPBCtialZCYSSxAEjo/Ah2ko2tJMpLmZoE8fQXPU0iQaI7EMIxVFyVX86vrXAscCuwGMMZ8AA7M1KSUzsXjcNQ35KRkRTShDbZ3jL2qoxREELSoIFCVf8SsImo0xLc4HO6lMPY2dSDRmXAEQ9KEROD4CJ53MT+lqaNUImlQjUJS8xa8geFNEbsNqYj8NeBb4V/ampWQi6ukjSL2wR9p4hv1ULAU1DSlKd8Bv1NCtwOXAUuC/gJeBP2RrUkpmYgl5BMHEzOI04wEmfOFECkMBPpH0GoSDmoYUJf/xGzUUF5EXgBeMMVVZnpPig0gs7oaNOhpBunBQx0fw1fOvpLggyKGYOL8AACAASURBVEP/+cSXj6A5agkA1QgUJX9JaxoSi5kiUg2sAlbZ3cnu3DfTU1JhaQTWtvMzrbM41j6PwE/UUIv6CBQl78nkI7gJK1roKGNMf2NMf2AqcKyI3JT12SkpiST4CNyEsnTho/ax/7nufH5y9TcIiL+icy0xNQ0pSr6TSRBcBJxvjFnv7DDGrAO+BXw7mxNT0hOLx9s5i9PVGnKLztmffTuLI6oRKEq+k0kQhI0x1W132n6CcHampPghGksoMeE6i9OMb6Mt+K0+6moEkTQXVxQlp8kkCFr28JiSZazwUWvbj0bgFKkTWpPQ/GUWq7NYUfKdTFFDE0Vkt8d+AYqyMB/FJ4lF5/w4i2MJ48ExDWV+y1dnsaLkP2kFgTFGC8t1URJ9BH6dxQERpn7lawB8piUmFEWxyWpdYRGZLiKrRGSNiNyaZtz/ExEjIpOzOZ98IupRdC5T+GhAhGnnfJtp53y7wyUm1DSkKPlL1gSBiASBh4GvAmOA80VkjMe4EuAGYEG25pIrtETj/OiFZWyrbco4NqlDmeMjyOAsDgSE5qZGmpsaCXQ0s1gFgaLkLdnUCKYAa4wx6+yCdU8BZ3qMuwf4HyDz6pfnrNlWxxPvfcq7a2oyjk3sUBb0oRHE4oagwM9uuoSf3XSJ7+qjbtE5NQ0pSt6STUEwGNiY8LnS3uciIkcAQ40xL2VxHjlDQ0sU8OeYjcZNQokJa1+6N/zE/gVgCQ9fCWWqEShK3tNpvQdFJAA8CHzPx9grRaRcRMqrqvK31FG9/dbtRxAkFZ3z2aoykBQ1lDmzOB43CXkEKggUJV/JpiDYBAxN+DzE3udQAowD3hCRCuBoYLaXw9gY86gxZrIxZnJZWVkWp9y5NDTbGkE0c1inV4cyP1FDDn5qDbUkOB00akhR8pdsCoL3gYNFZKSIFADfBGY7B40xu4wxpcaYEcaYEcB7wBnGmPIszqlL0zGNIE4woYAcZKg+mtDIxjknk48gURBoHoGi5C9++xF0GGNMVERmAP/GanT/mDFmuYjcDZQbY2anv0L3w/ERNPvQCJLCR322qgwGhC997RwAdgUym4aaE8pKqGlIUfKXrAkCAGPMy1hNbBL3eZawNsYcn8255AL1zf41gkRTj4hkLBnhJKAdd9q5ALz40WcZBYGjERSHg2oaUpQ8JquCQOkYrVFDmTUCr5IRaWsN2bWJandud8enK1IH0GwLpL49wtTUa2kpRclXVBB0IRrst+5mHxpBJB5PsvkHA+mdv9GYFWX0yx9eDcDka3/pWyPoUxxm866mdsJHUZT8oNPCR5X2uBpBNL0giMcNxtAmHFTSOotjCXkHYBWqyygIbF9F72Kr4rg6jBUlP1FB0IVwfATNGUxDTm+B5IU9g0bQLo/AihoyaYSB47TuawsCdRgrSn6igqAL4VcjiNrG/aRM4QwJYon9CxLPTRdC6mgEfRxBoA5jRclLVBB0IVqjhvxpBElv+AFJW2Ii2rbEhI+QU6cpTd8eahpSlHxGncVdCL+1hqK2M6B9glj6onOhoPCVs79lXcNHobp2GoEKAkXJS1QQdCH8ZhZ7m4bSO4sj8TgFoRDHTDsdgHfWWK2o04WQNqtpSFG6BSoIuhCNLf5MQ44JKCmPIJApoczyEdRs/cwaLwVAJtNQctSQagSKkp+oIOhC1PssMdFqGkrWCNJ3KLNyAH4z8yYApt3yCNAx05D6CBQlP1FncReiodlfQpkbPprw7WVqPRlN6HEM/qKG3PDRHpb2oBqBouQnKgi6CC3RuJvJmzF8NNbeRxCQ9FFDMY8y1JDenNQ+fDRz6QtFUXIPFQRdBMc/0Kc4TCRm0oeCxtubhjKVlU7scWyNt35q1JCiKCoIugiOf2BAT8sMk84e7+UsDgbSt6qMxYybOwCtOQjpCtU1R2OEAkLPwmDGOSmKkruos7iL4OQQ9OtZANX1NEVi9Cz0/noirmmodV8wIGmdzBHbR3DqBVfY5/rLLC4IBSgIBgiICgJFyVdUEHQRnMqj/W2NIN2iHktlGsrkIwgIR3zpJABWfLYLSO8jaI7GKQwFEBHtSaAoeYwKgi6CU17Cj2nIs8SEHx+BCJ99utYaX2D1fs7kIygIWdbDonBQfQSKkqeoIOgiJJmGSJ9U5pVHkK7WUMwtWw2P3XcbAOfN/AOQwTQUi1MYsvwDBaGA6zxWFCW/UGdxF8EpL+FqBGlCSJ0SE0nO4jTVR93xHQgffXLBBj7ZWktjJMaTCzbQEo2zamut38dRFCWHUEHQRWhotjSC/n5MQymKzqWKAPL2KVg/M5WuDtkDQ8H0eQqKouQuKgi6CI5G0M+Hs9grjyBdq8pIzNunAOlNQ0mCIBBwBZCiKPmFCoIugqMROKahdGUmPIvOpak+2qoRtO4L+ihDHY0ZQnYdi1BAiGTqdq8oSk6izuIuQkMkRkEwQC87dyCts9ijDHW6VpWJPoWvX3pd0rmZ2lsWhy1ncSgormahKEp+oYKgi9DQHKW4IEhROHMWr2Oi8e0sTogyGjfliwBs3tUIpNcIYm1MQ02RqN/HURQlh1BB0EWob4nR06cg8DL1pKs+mugsrli9HIDiQQdax9L5CGKGoGMaCoqb0awoSn6hgqCL0NASpUdhiEI7gaspQ7kI8F99NLFs9V9/fjcA/3X/X4BMUUNxwq5GIO51FEXJL9RZ3EVoaIlRHG7VCJrT+AhiHpnFwYCVWWw8FvaYp+Cwfqb3ERjX/BQKBnyFjza0RPnh80vZ2dCScayiKF0DFQRdhKaIJQiCASEclLQJZY7TNuiZF5B6fFvncqrxDu2ihnyYhj7cuIu/L9zA/LU1GccqitI1UNNQF6EpEqe+OcqTCzYQEOHDjTt5csEGAC6YOixpbOsbfuu+oKQOB01VpC7VeIdoPJ7gLPZnGqq3w2Cr65ozjlUUpWugGkEXoSkSc9++w8FA2lBNz6JzgdThoJ6tLTNkFhtjkqOGggG3M1o66mxBUFWnpiFFyRVUI+giNEVi9LY7gYWCknbR9Sw6J6kbzSS2tjzv6puBBA0iVaE6Y4gbCIdao4bixtIuEsNW21KrGoGi5BwqCLoITZE4A3rZGkEgQMRXq8rWfels/okaxIETJtv3i6UcD63CJpyQRwBWaerigmDKudU12YKgVgWBouQKahrqIjRFY4TtXpLhjBqBZbuXxFpDjkbgsbIn+ghWf1TO6o/KM/oIWuz7JzqLwWpfmQ71EShK7pFVQSAi00VklYisEZFbPY5/V0RWiMhHIvK6iAzP5ny6Mk2RGOGAY4YJpI3Q8TLPpLP5O9cKCjzzm5/xzG9+ljF81NEIChISyoCMPQnqXEGgPgJFyRWyJghEJAg8DHwVGAOcLyJj2gz7AJhsjJkAzALuz9Z8ujLGGJoi8QRncfq6PtG4IRxM/uqCaZzFXnkHrc3rve8RcTUCW0uxhVS6qqgAtbZpqEY1AkXJGbKpEUwB1hhj1hljWoCngDMTBxhj5hpjGuyP7wFDsjifLouzuDqmIavkc3rTUHuNII2z2CN81NlKZRpyBIGjEQSD/kxDdc0RwCqZoT2OFSU3yKYgGAxsTPhcae9LxeXAK14HRORKESkXkfKqqqq9OMWugeO4DXdAIwi1FQSuRuAx3qMfgYgQSFOozrm/q6W4PoL0GoHTexnUT6AouUKXcBaLyLeAycDPvI4bYx41xkw2xkwuKyvbt5PbBzglp8OJeQRpav/H4sY12TgE0/gIoh4JaNZn8RQckKgRtOYRgA/TUHPUvU+VCgJFyQmyGT66CRia8HmIvS8JETkJuB04zhjTLVeOVo3AWkEzNYqPxIwbzung2vzT+AiCInzrpjuTzslkGnIEgGOKSlcDCaCuKcKQfj3YsL1BQ0gVJUfIpiB4HzhYREZiCYBvAhckDhCRw4HfAdONMduyOJcuTaMtCJxFtyBj1FC8nUaQLhw0MY9gxCFjE87J7CMItzMNZQofjXHIoBJLEGjkkKLkBFkzDRljosAM4N/Ax8AzxpjlInK3iJxhD/sZ0At4VkSWiMjsbM2nK9NWIwiHrBITKRdpj/DRYCCNszghE3nZwnksWzjP/ZzJRxBuYxryEz46vH8PQH0EipIrZDWz2BjzMvBym313JmyflM375wptfQROpE4kGqcw3D6LNxbzcBZLamdxYpG6F/70EADjpnyRoA8fQbhdQllqQRCPG+qao/TrWUDvopAKAkXJEbqEs7i745ScdgWBXd+nJYV5yIoaapNHkNZZ3L61JWTyETgaQWuSG6QXBPUtVg5BSWGI0pJCFQSKkiOoIOgCNHs4iyG1GSbq5SNIV33Uo0id9TmzjyDk5jZkzix2Qkd7FoYo7VWoPgJFyRFUEHQBHGexk73rmIZSaQQxrzyCDiaUOZ9TFZ2L2PWMnHNCPhLKnGSyXkUh+vcoYEe9CgJFyQVUEHQBHB9ByKdGYC3SKUpMeCzsjo/AKxs5VfvJSCy5jEXIR4kJp7xESWGIkqKQW3dIUZSujZah7gI4UUMFwY5oBG3yCNJUH3Xs/SJw2a0/bT0nkN40FE4wP7kaQZo8Amfh71UUoldRyC1JrShK10YFQRegVSNIdhZHUvoIDEVh7/DRVK0qA2IJiwOGH+jutzKL0wmCQNLYgEBLLLVpyClB3bMgRElRmLqWKPG4SSptoShK10NNQ1lk4frtTP/FWzS0pH8zbk0os01DGSJ0op7ho9bPVK0qHSGz+O05LH57jn1Oah9BNNa+wmkoGEipETy5YAOvrbByAv+zchufbK3FmNZIIkVRui4qCLLIm6u3sXJLLRu3N6Yd1xyJURAKuOadsI/w0WCqEhMpWlU6guPlJ3/Py0/+3jonQ9RQ28ikUEDS+ggcR3JRKECRnf9Qq+YhRenyqCDIImu31QNQlaHmTlMkRlGo9asozGAaisWT7feQmFDmrRF49RkOBMRTcEB70xBYgiBd+Khj4ioIB9xnUIexonR9VBBkkbVVdQBsq21KO64pktwHOJzBWRyNeZSYcMNH24/3CjeFTNVHTTthEwoG0oaPtkRjhAJCKJCoEURSjnd4Z021Jp8pSieigiBLRGNxKmp8agTRmLtwguX4DaZ5+/bqUOZYijL5CBIJpq015K0RpDMNNUXjribgaDiZTEORWJxL/rSQX/9nTdpxiqJkDxUEWWLjjkY3bDOTIGhsiVEUSq4pVBAMpNEI2ncoC6arPprgI0gkc/hoW2dxetNQcyTm1kZyfmYyDVXXNROJGT7YsCPtOEVRsoeGj2aJtdvq3O1MDVqaonGKwsmLrtWTIEVj+TQdyrxs/onN7q+e+fPWczJUH22vEQQyOIvjribg11m8dbf1u1mxebflK/EosqcoSnZRjSBLOP6Bgwb28uUsbltlNJ1G4NWhLCCCkNo05CzqA/Y7gAH7HeCek676aHsfgaT1ETRFWqulus7ijIKgyb6fYcXm3WnHKoqSHVQQZIm1VXWU9irkoLLMgqDZ403Y0gi8F12vEhOQOi8gGm81Jc1/7V/Mf+1f9vgOmoYy+AgaWqL0sJ3eBaEAQmZn8baE382SDTvTjlUUJTuoIMgSa6vqObCsJ2UlhZlNQ5E4xW1MQ+FgatNQLGU4qHeJicQEtNef/yuvP/9Xe7y3aSgSixM3tNcIAulbaNa3xOhZYFkbAyIUhALUZvARbNvdREBgYEkhSzaqIFCUzkAFQZZYV1XHqLJelJUUsrMhktak0uihERSGUrerjHiYhiC1zd/LlOSM9xIcrR3T2juLU2kEcWNobInSo7D1OYrCQR8+gibKSgo5Ylg/PqxUQaAonYEKgizQFImxoyHCAX2KKCspBKAmTW1+K6EsWRCEUzSwN8akjAIKBrwX9ohHJjJAcTjolrdInk9ydzJ3ToGA2zuhLc0RS4twNAKwhFlmH0EzA0uKGD+kD5/WNPjKO1AUZe+igiALOD6Bgb0LKetVmLTPCytapk3UUApn8e6mKHEDfYsL2h1L5SOIxb0FR8/CEE2ReDuB07aHskMwKCkd2E5NoR4FyRpBpvDRbbXN7Ne7kCH9ioFW57GiKPsOFQRZwHGArvhsN4vt+PhZiyp5csEGnlywod14K3y0rbPYO2a/xvY3lJa0FwTBgHc10UjUO7O4p23G2dGQrK00uUXw2moEkrLoXINTebQwWSPI6Cze3cTA3kXs17sIgC27NMNYUfY1mkeQBarskhIlRWH3DTmViSQeN7R4CYJg0PPt22n/WNqrsF0xu2BAiHjEg9bUNzN6UAkAN/z3b9z9vexFu7qu2V2IobUaaoFX9dEUPoL6FuucthpBKmfxkws2EI3HqalvYevuJt5fvx2ALaoRKMo+RzWCLOBoBCVFIXexrW32fjN2Gtd7aQSxuGln83dq8gzoWdjuWiWFIU/n7DbbDg9Q0rc/JX37A632/O31bTWC5I5pDqGAZRry0jrqU2oEqU1DjnDsXRSmd3EYUNOQonQGKgiywNbdTQQDQs/CEKFggOI00TPOouvlI4D27Sqr05iGeheH2d2YLHAaW2LUNkddp/WbLz7Lmy8+C7RqBG0d2W07pjm4Dew9NJUGWyNIdBYXhYNpncW1riAIEbZ/T1t2qSBQlH2NCoIOsK6qjvcrtmcct213M6W9CtzS0H2Kw+xsSKERRFJpBNbntotudV0LItC/h4cgKAqxuymCSQghdSqfOqaft1+axdsvzQJa397bVv5sTOEjCKVpmFPfEiUUkCQHc2E4QGMkljIMdrftPygpsrSB3sUhX6ahDzfudH0viqJ8flQQ+MQYw7VPfsCVfylPWmi9sCJhWm3u/XsWtDO/OLQKgra1hqwFtW1Pguq6Zvr1KPCsJtq7OEwkZpLs8k4tn4El7U1JReEAAfEyDXlHDbX2LW4fQtrQHKNnYQiR1nOckNj6FH6C3U6z+yJLIPUuCvsyDd36/FIueWyhlq5WlL1EtxUEkVicK/9Szp/eWe9r/Burqvh48252NERYV12fduy22uakhXdAzwJ2NLR4Jns5pqFij1pDAM1tNYJaS9vworf9Zr01wbziaAQDe7cXBCKW+SqVaahtHoFz/c0e5pv6hPISDo5wS2UW29UQIWjPASxBlsk01NASZdWW3exuivLfL69MO1ZRFH90W0Hw6/+s4dUVW3mmvNLX+EfeWEOJvWAt+jS9WWLb7ibKShI0gl4FROOmnf0eWuPv25qG3HaVHhpBaa/2izrgOlwTzSvbbI1gv4T5JNKrMERNCmdxW0EwoKclgNZ7CMKGhPISDoWh9BVIt9U2MSDBhNa7KEx1XTPRFKYkgGWbdhM3MHFIH55bXMnyz3alHKsoij+6pSBYtmkXv567hpKiECu37GZXCvu9w+qttbxfsYMbTjqY3kWhtLXzIzErJDJZI7C2vcxDTrnqkaU9k/YX2otwW/t6TX1LakFgm1gccxDA1tomCoIB+vYIe57TszBETb23j6Ctaah/zwICgqdGVN+cXF4CWoVbqqSytia03sUh4iZ92e4P7XpE958zEYB5n1SnHKsoij+6pSD455JNBEV48LxJGAMLMziAF9gx7qeMHcThw/qx+NPUNXEcu3VbHwHQ7s0bYOWWWnoUBBnar0fS/pQaQW0zA1KZhjxCMKt2N1NWUuja7m/++ePc/PPH3eM9C4JpfATtncWD+xV3QCNwTEPtBW1LNM6O+pYkk1Uf2/SUzjy0pHIng/sWM3pQCcMH9OADrViqKJ+bbplQNn9dDZOG9eVLB5dSEAqwcH0N08bsl3J8ecV29utdyFurqwgFhdVba3ls3nr3jfeCqcPcsdsSnLNOPkGf4rCnUxZg1ZZaDt6vxG0s4+AVPtrYEqO+JZZSI/AKwdxW25y02BYWFSed06swxNqq5IV9Q00DPQtDrskmkZGlvahoIwgisTiNkVg7jaCXraFs2pmc+AZWyQ1DsskqXS6Bk5H97ppqhvTrwZMLNtCvRwGLN+zAGJPkpG5LUyTGhu0NHLJfScoxitKd6XYawa6GCMs/280XDhzA84s3cUCfYl5eusUt/+BVAqK8YgeTR/RHRBjWvwcG2Li9wfP6ziKWuPgGA0K/HgXtNAJjDKu21nKoxwLVqzBEQJJDO53tshSCACzzSuJCuq22KclM9dqsv/DarL+4n3sWhqhrjrpaAFga0ogByRqKw8gBPVhfXZ8UOeWExrbVCPoWh9m/T5GrUSWy1cOJ7fo4UmgEdc1RdjRE3LpEQ/sVs6222dN5nchPXlrByT9/i4sfW0jlDu/vTVG6M91OECxYX4MxcMyoAYBlm/9sZ2PSQpjIpp2NbNrZyFHD+wEwrF8PQgHh4y3e3bQcLWBgG+esFUKabPuuqmtme32LW/4hkcJwkKH9e7B6W627L10ymUPbEMytCVnFAAtef4kFr7/kfnYidhxtZfOuRip3NDJiQLLPwmFkaU/qmqNJdnynVlHbqCER4ehRA1iwrqZdyO02O+kuMUO6Z0GQgmAg5cLudH1zzGhD+1s/0+UU7KhvYdaiSsYP7kN5xXZmzl6RcqyidFe6nSCYv66GwlCAScP6AnDooBIMqReTctt/MHmEVZahMBxkzAG9+XDjLs/olv+s3EZprwI3k9dhQC8rlyBxQVy1pdadgxej9yvhs51NbgioU2fIq7yEQ++isBs11BSJsasxwn4eoaMOzlu8E0K60H57TykIynoBUFHd+mbtmMMSy0s4HD2qP9V1Le4i7rB1dzNlvQqTGuyICJOG9eWVZVs8y2mXV2ynb48ww2xtZVCfIgpDAU8/gaPd3frcRzRF4pxw6ECmjBzA6yu3sq7NXNqyuynCH95ex1MLN6gGoXQLsioIRGS6iKwSkTUicqvH8UIRedo+vkBERmRzPtFYnLdWVzF5RD83tHFo/x4M79+DeWuqPRefd9ZU07MgmLRYHzGsH42RGCu31CaNXVdVx39WbuNbRw9v10Gsf89CmiLxpAgaRxB4aQQAB9smo7dXW5ExrRpBetNQVW0zsbhpLYedInQUoJdt13cih8ordtCzIMigPt7njLQFxPrq1sX08XfXUxgKsL/HOVNHWprX/HXJ5qFttU2euQ3fPmY4G7Y38ObqbUn7a+qaWVtVz+Th/V3fRSgQYPzgPsxdtc1To2tsiTF/XQ0HlvVkUO8ijh7Vn3AwwB/npc4daYnGueqJRfzkpY+59fmlnP7QvIyCQ1FynawJAhEJAg8DXwXGAOeLyJg2wy4HdhhjDgJ+DvxPtuYTjxtuee4j1lbVc97koUnHvnxIGTsbIry3roaoXb0zHjc8tXADz5RXcvrEA5IyeQ8a2IveRSHmr6txyyREY3F+//Z6CoIBLpw6vN39RwzogQBPvb+RxpYYDS1RFq7fTmmvQgaksPnv36eIXoUh5ny8lZ0NLbz9SRXQGs/vRUlRmLixBNhb9viydBqB/Rb/6grrHgvW13DE8H6erTABBvcrJhwU3lu3naZIjHfXVDPn420cf0gZPQraawTDB/RgUO8i3li5jcaWGMYYHpu3nh0NEfbv3V5wnDJ2EANLCnlsXoW7uNc1R3nrkyoCApNtE53DVccdyLqqeu54YZkbamuMob45yp/nV1DfEuOkw/ZzfzdnTRrMs+WVPPHep0RicVdD+9t7n/KL11Zz+kPzeHdtDf/viMHMOOEgRIRL/vQ+b39S1a7YXjxuqNzRwF/mV3D6Q/P48v1zOfPhd3hywQY+29nomYFujGFXQ4QPNuxg7qptvLFqG2ur6qhvjnq+iDi0ROPsaoiwZVcT2+tbUna8M8YQjxsiMavPRCxuMmbCK0o2o4amAGuMMesAROQp4Ewg0Uh7JjDT3p4F/FpExGThL/fhuWt4fvEmvjftEM6cNDjp2OhBJRzQp4iXlm7mlWWb+e+XV9IcjRE3lpD48Zljk8YHRPjCgaX83/It3PfKSn7+2mqidqXQc44c0s4sBDCkXw/OnTyUZ8s3Muau/0OAuIFTxw9KOeeACKP3K+GVZVt4ZdkWAC75woh2yWeJHFTWiz7FYb792EIAhvXvwaQhfVOO79+zgLMOH5zkKG/7+0kkGBCOHz2Qf3ywiReWbMIYGNy3mC8cVOo5XkT40sGlPLuokrF3/Z9VKjtmOGz/3hxt+2kSCQcDXHT0cP73tdUcduf/UWh3aosbOHxoX9eh7HDSmP24/isH86vXP2HWokqKw0FixirtLcD5U4YxPMHMdcv00Xy2q5EfvbCMH72wDBErQiuxT/PXxu/PkcMtU+AfL57M5X8u56I/LrTnJwQDgiBEYnGi9uI9fnAf+vcsYMuuJm77x1IAAmI9vzUeRHCfJRUFwQChoNVyNG6shT0WN57nhINCQARjIGYMcWNI9V9OQKy/J7HnJLR+VvaMzvjV3Xn6GL5x1LDMAzuIZOttQUTOAaYbY75jf74ImGqMmZEwZpk9ptL+vNYeU93mWlcCV9ofRwOrUty2FOiOGUbd8bm74zODPnd3Y28+93BjTJnXgZzIIzDGPAo8mmmciJQbYybvgyl1Kbrjc3fHZwZ97s6ex75mXz13Np3Fm4BEY/wQe5/nGBEJAX2AmizOSVEURWlDNgXB+8DBIjJSRAqAbwKz24yZDVxsb58D/Ccb/gFFURQlNVkzDRljoiIyA/g3EAQeM8YsF5G7gXJjzGzgj8ATIrIG2I4lLD4PGc1HeUp3fO7u+Mygz93d2CfPnTVnsaIoipIbdLvMYkVRFCUZFQSKoijdnLwRBJnKWeQjIlIhIktFZImIlHf2fLKFiDwmItvsvBNnX38ReU1EPrF/9kt3jVwkxXPPFJFN9ne+RERO7cw57m1EZKiIzBWRFSKyXERusPfn9fed5rn3yfedFz4Cu5zFamAaUIkVsXS+MSavS02KSAUwuW0CXr4hIl8G6oC/GGPG2fvuB7YbY+6zBX8/Y8wPOnOee5sUzz0TqDPGPNCZc8sWIrI/sL8xZrGIxVJMYwAAAfJJREFUlACLgK8Dl5DH33ea5z6PffB954tG4JazMMa0AE45CyUPMMa8hRVVlsiZwJ/t7T9j/UeTV6R47rzGGLPZGLPY3q4FPgYGk+ffd5rn3ifkiyAYDGxM+FzJPvwldiIGeFVEFtllOLoT+xljNtvbW4DULebyjxki8pFtOsorE0kidjXiw4EFdKPvu81zwz74vvNFEHRXvmiMOQKrwuu1timh22EnIea+jdMfvwEOBCYBm4H/7dzpZAcR6QU8B9xojEnqApXP37fHc++T7ztfBIGfchZ5hzFmk/1zG/APLBNZd2GrbVd17KvbMozPC4wxW40xMWNMHPg9efidi0gYazH8mzHmeXt33n/fXs+9r77vfBEEfspZ5BUi0tN2KiEiPYGTgWXpz8orEsuTXAz8sxPnss9wFkObs8iz71xEBKviwMfGmAcTDuX1953quffV950XUUMAdljVL2gtZ3FvJ08pq4jIKCwtAKxSIU/m6zOLyN+B47FK8m4F7gJeAJ4BhgGfAucZY/LKsZriuY/HMhMYoAL4rwTbec4jIl8E3gaWAk4v2Nuw7OV5+32nee7z2Qffd94IAkVRFGXPyBfTkKIoirKHqCBQFEXp5qggUBRF6eaoIFAURenmqCBQFEXp5qggUBRF6eaoIFAURenm/H8s/K7X+umlBQAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stdout","text":[" 가장 긴 문장은 25 개의 단어를, 가장 짧은 문장은 1 개의 단어를 가지고 있습니다.\n"]}]},{"cell_type":"code","metadata":{"id":"CeteJ2oBJtDQ"},"source":["## preprocessing\n","punct = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\n","punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n","\n","def clean_punc(text, punct, mapping):\n","    for p in mapping:\n","        text = text.replace(p, mapping[p])\n","    \n","    for p in punct:\n","        text = text.replace(p, f' {p} ')\n","    \n","    specials = {'\\u200b': ' ', '…': ' ... ', '\\ufeff': '', 'करना': '', 'है': ''}\n","    for s in specials:\n","        text = text.replace(s, specials[s])\n","    \n","    return text.strip()\n","\n","cleaned_train_corpus = []\n","cleaned_test_corpus = []\n","# train.title = train.title.apply(lambda x : hanja.translate(x, 'substitution'))\n","# test.title = test.title.apply(lambda x : hanja.translate(x, 'substitution'))\n","\n","for sent in train['text_sum']:\n","    cleaned_train_corpus.append(clean_punc(sent, punct, punct_mapping))\n","    \n","for sent in test['text_sum']:\n","    cleaned_test_corpus.append(clean_punc(sent, punct, punct_mapping))\n","\n","\n","def clean_text(texts):\n","    corpus = []\n","    for i in range(0, len(texts)):   \n","\n","        review = re.sub(r'[@%\\\\*=()/~#&\\+á?\\xc3\\xa1\\-\\|\\.\\:\\;\\!\\-\\,\\_\\~\\$\\'\\\"]', '',str(texts[i])) #remove punctuation\n","        review = review.lower() #lower case\n","        review = re.sub(r'\\s+', ' ', review) #remove extra space\n","        review = re.sub(r'<[^>]+>','',review) #remove Html tags\n","        review = re.sub(r'\\s+', ' ', review) #remove spaces\n","        review = re.sub(r\"^\\s+\", '', review) #remove space from start\n","        review = re.sub(r'\\s+$', '', review) #remove space from the end\n","        review = re.sub(\"[一-龥]\",'', review)\n","        review = re.sub(\"에서\",'', review)\n","        review = re.sub(\"으로\",'', review)\n","        review = re.sub(\"에게\",'', review)\n","        review = re.sub(\"의해\",'', review)\n","        review = re.sub(\"에도\",'', review)\n","        review = re.sub(\"을\",'', review)\n","        review = re.sub(\"및\",'', review)\n","        review = re.sub(\"를\",'', review)\n","        review = re.sub(\"에\",'', review)\n","        review = re.sub(\"하여\",'', review)\n","        review = re.sub(\"대상\",'', review)\n","        review = re.sub(\"등 제공\",'', review)\n","        review = re.sub(\"위해\",'', review)\n","        review = re.sub(\"제공\",'', review)\n","        corpus.append(review)\n","    return corpus\n","\n","basic_preprocessed_train_corpus = clean_text(cleaned_train_corpus)\n","basic_preprocessed_test_corpus = clean_text(cleaned_test_corpus)\n","\n","\n","stopwords = []\n","with open(STOPWORDSPATH) as f:\n","    for line in f:\n","        stopwords.append(line.strip())\n","\n","removed_stopword_train_corpus = []\n","removed_stopword_test_corpus = []\n","\n","for tagged in basic_preprocessed_train_corpus:\n","    tagged=mecab.pos(tagged)\n","    \n","    temp = []\n","    for tag in tagged:\n","        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n","            continue\n","        temp.append(tag[0])\n","\n","    removed_stopword_train_corpus.append(' '.join(temp))\n","    \n","for tagged in basic_preprocessed_test_corpus:\n","    tagged=mecab.pos(tagged)\n","    \n","    temp = []\n","    for tag in tagged:\n","        if tag[0] in stopwords or tag[1] not in [\"NNG\", \"NNP\", \"VV\", \"VA\", \"VCP\", \"VCN\", \"MM\", \"MAG\", \"XPN\", \"SL\", \"SH\"]:\n","            continue\n","        temp.append(tag[0])\n","\n","    removed_stopword_test_corpus.append(' '.join(temp))\n","\n","\n","train_text = removed_stopword_train_corpus\n","test_text = removed_stopword_test_corpus\n","train_label1 = np.asarray(train.digit_1)\n","train_label2 = np.asarray(train.digit_2)\n","train_label3 = np.asarray(train.digit_3)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NKyjChFYvoLu"},"source":["train['text_all_clear'] = train_text\n","test['text_all_clear'] = test_text"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayZdkh3jwG_6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668976041,"user_tz":-540,"elapsed":517,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"8047c636-58fd-4622-c1f8-f204ada0f7bb"},"source":["train_length = train['text_all_clear'].astype(str).apply(len)\n","train_length.max()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["88"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["test_length = test['text_all_clear'].astype(str).apply(len)\n","test_length.max()"],"metadata":{"id":"qOrw_Bg20zpd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649668976041,"user_tz":-540,"elapsed":5,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"42387867-3e7f-464b-b48d-c2794696cff4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"c8eyZF_X1Zzc"},"source":["train.text_sum = clean_text(train.text_sum)\n","test.text_sum = clean_text(test.text_sum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MPj6TBCou3rO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649669008739,"user_tz":-540,"elapsed":2379,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"38c871c3-630f-456f-f722-a23ecb97203b"},"source":["train_data_text = list(train['text_sum'])\n","\n","train_clear_text = []\n","\n","for i in tqdm(range(len(train_data_text))):\n","  train_clear_text.append(str(train_data_text[i]).replace('\\\\n', ''))\n","train['text_all_clear'] = train_clear_text\n","\n","\n","train_clear_text = list(train['text_all_clear'])\n","\n","train_clear_text2 = []\n","\n","for text in train_clear_text:\n","  temp = re.sub('[-=+,#:;//●<>▲\\?:^$.☆!★()Ⅰ@*\\\"※~>`\\'…》→←]', ' ', text)\n","  train_clear_text2.append(temp)\n","train['text_all_clear'] = train_clear_text2\n","\n","\n","test_data_text = list(test['text_sum'])\n","\n","test_clear_text = []\n","\n","for i in tqdm(range(len(test_data_text))):\n","  test_clear_text.append(test_data_text[i].replace('\\\\n', ' '))\n","test['text_all_clear'] = test_clear_text\n","\n","\n","test_clear_text = list(test['text_all_clear'])\n","\n","test_clear_text_final = []\n","\n","for text in test_clear_text:\n","  temp = re.sub('[-=+,#:;//●<>▲\\?:^$.☆!★()Ⅰ@*\\\"※~>`\\'…》→←]', ' ', text)\n","  test_clear_text_final.append(temp)\n","test['text_all_clear'] = test_clear_text_final"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1000000/1000000 [00:00<00:00, 1480826.73it/s]\n","100%|██████████| 100000/100000 [00:00<00:00, 1694367.06it/s]\n"]}]},{"cell_type":"code","source":["train_length = train['text_all_clear'].astype(str).apply(len)\n","train_length.max()"],"metadata":{"id":"Cf6k12J5Bsxh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649669009072,"user_tz":-540,"elapsed":344,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"2a989da2-5946-4b98-c526-67ec788d8afd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["84"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"4bYfpXXE5Tea","colab":{"base_uri":"https://localhost:8080/","height":174,"referenced_widgets":["ed863819865c4341b0ba285971539386","3460dbbf9cdf4740b1c7e82ed94e0b94","aa3a72af733c48a780703a85acf84c59","a668c301626c4e8d97ecd544bf94263a","e997a6b066594bf49646ee0a37f53d6b","e69118e138ff4eaab055d0db8df7e58a","9ae4f3b73b694d8b99fdb2246da266fd","efe1ed11492f4d97ae64a9bc6208b937","3ca539ace3ae430ea23cc5015e1d0c03","544ecca8792c46deb4fe6779a8ff467a","6ca2992d1b9f4abfac950adab8295136","fd10a186c2df476c84772d255c279d85","7a30416ea3914c48ac2a1f89084388d0","e7b14906fc5d4350925b8dc5074ae93a","9c1608db032c4315ad49114894ca7024","a04aae9e0d7c446594d41edb7e4f7d11","28175c7380b94407b105cfe716038392","041f8ea3951d4efb81a4b84386da9461","388579c13c2e40eaad1c51068ba4e743","83b3092e4eeb49e29a49672896da96f7","d6b6b2d9e21c40778a0e1e35a7f2afde","6b6f98f657db4d1aa190519666778b97"]},"executionInfo":{"status":"ok","timestamp":1649669011484,"user_tz":-540,"elapsed":2413,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"bd4d410c-d44d-4587-c5a7-31113ebef758"},"source":["tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/371k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed863819865c4341b0ba285971539386"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/77.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd10a186c2df476c84772d255c279d85"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1321: FutureWarning: The `max_len` attribute has been deprecated and will be removed in a future version, use `model_max_length` instead.\n","  FutureWarning,\n","Setting 'max_len_single_sentence' is now deprecated. This value is automatically set up.\n","Setting 'max_len_sentences_pair' is now deprecated. This value is automatically set up.\n"]}]},{"cell_type":"code","source":["len(train['digit_1'].unique())"],"metadata":{"id":"lHfa3Z7MoYeb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649669011484,"user_tz":-540,"elapsed":13,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"60dc2291-518f-4c9b-b7c9-fa5f1b1d8444"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["print('train_label1 count : ', len(train['digit_1'].unique()))\n","print('train_label2 count : ', len(train['digit_2'].unique()))\n","print('train_label3 count : ', len(train['digit_3'].unique()))"],"metadata":{"id":"0l9_GuVzfyGU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649669011484,"user_tz":-540,"elapsed":10,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"47206bda-c5bd-489e-ea30-a96be3d7fac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_label1 count :  19\n","train_label2 count :  74\n","train_label3 count :  225\n"]}]},{"cell_type":"code","metadata":{"id":"2YqTZBolw3HL"},"source":["model_name = 'monologg/kobert'\n","SEED_NUM = 42\n","tf.random.set_seed(SEED_NUM)\n","np.random.seed(SEED_NUM)\n","BATCH_SIZE = 84\n","NUM_EPOCHS = 10\n","VALID_SPLIT = 0.2\n","MAX_LEN = 84\n","NUM_CLASS = 225\n","K_SPLIT = 5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p_xHB5wRmoS9"},"source":["def bert_tokenizer(sent, MAX_LEN):\n","\n","    encoded_dict = tokenizer.encode_plus(\n","        \n","        text = sent,\n","        add_special_tokens = True,\n","        max_length = MAX_LEN,\n","        pad_to_max_length = True,                                   \n","        return_attention_mask = True,\n","        truncation = True \n","    )\n","\n","\n","    input_id = encoded_dict['input_ids']\n","    attention_mask = encoded_dict['attention_mask']\n","    token_type_id = encoded_dict['token_type_ids']\n","\n","\n","    return input_id, attention_mask, token_type_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_clean = train[['text_all_clear', 'digit_3']]"],"metadata":{"id":"916-2NM6pcy1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","target = train_clean[\"digit_3\"]\n","\n","for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(train_clean, target))):\n","    train_df = train_clean.iloc[train_idx]\n","    valid_df = train_clean.iloc[val_idx]\n","\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    train_data_labels = []\n","\n","    for train_sent, train_label in zip(train_df[\"text_all_clear\"], train_df[\"digit_3\"]): \n","        try:\n","            input_id, attention_mask, token_type_id = bert_tokenizer(train_sent, MAX_LEN)\n","        \n","            input_ids.append(input_id)\n","            attention_masks.append(attention_mask)\n","            token_type_ids.append(token_type_id)\n","            train_data_labels.append(train_label)\n","        \n","        except Exception as e:\n","            print(e)\n","            print(train_sent)\n","            pass\n","\n","\n","    globals()['train_news_input_ids_{}'.format(fold)] = np.array(input_ids, dtype=int)\n","    globals()['train_news_attention_masks_{}'.format(fold)] = np.array(attention_masks, dtype=int)\n","    globals()['train_news_type_ids_{}'.format(fold)] = np.array(token_type_ids, dtype=int)\n","\n","\n","    globals()['train_news_inputs_{}'.format(fold)] = (locals()['train_news_input_ids_{}'.format(fold)], locals()['train_news_attention_masks_{}'.format(fold)], locals()['train_news_type_ids_{}'.format(fold)])\n","    globals()['train_data_labels_{}'.format(fold)] = np.asarray(train_data_labels, dtype=np.int32)\n","\n","\n","for fold, (train_idx, val_idx) in tqdm(enumerate(skf.split(train_clean, target))):\n","    train_df = train_clean.iloc[train_idx]\n","    valid_df = train_clean.iloc[val_idx]\n","\n","    input_ids = []\n","    attention_masks = []\n","    token_type_ids = []\n","    valid_data_labels = []\n","\n","    for val_sent, val_label in zip(valid_df[\"text_all_clear\"], valid_df[\"digit_3\"]): \n","        try:\n","            input_id, attention_mask, token_type_id = bert_tokenizer(val_sent, MAX_LEN)\n","        \n","            input_ids.append(input_id)\n","            attention_masks.append(attention_mask)\n","            token_type_ids.append(token_type_id)\n","            valid_data_labels.append(val_label)\n","        \n","        except Exception as e:\n","            print(e)\n","            print(val_sent)\n","            pass\n","\n","\n","    globals()['valid_news_input_ids_{}'.format(fold)] = np.array(input_ids, dtype=int)\n","    globals()['valid_news_attention_masks_{}'.format(fold)] = np.array(attention_masks, dtype=int)\n","    globals()['valid_news_type_ids_{}'.format(fold)] = np.array(token_type_ids, dtype=int)\n","\n","\n","    globals()['valid_news_inputs_{}'.format(fold)] = (locals()['valid_news_input_ids_{}'.format(fold)], locals()['valid_news_attention_masks_{}'.format(fold)], locals()['valid_news_type_ids_{}'.format(fold)])\n","    globals()['valid_data_labels_{}'.format(fold)] = np.asarray(valid_data_labels, dtype=np.int32)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YC-oZ2O1mxLK","executionInfo":{"status":"ok","timestamp":1649669771971,"user_tz":-540,"elapsed":760494,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"c5f53c8a-b862-41b6-8c17-d4d887a507ff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","5it [10:08, 121.78s/it]\n","0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py:680: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n","  UserWarning,\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n","5it [02:31, 30.30s/it]\n"]}]},{"cell_type":"code","source":["class TFBertClassifier(tf.keras.Model):                                                \n","    def __init__(self, model_name, dir_path, num_class):\n","        super(TFBertClassifier, self).__init__()\n","\n","         \n","        self.bert = TFBertModel.from_pretrained(model_name, from_pt=True) \n","                                                                                                                                    \n","        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n","        # self.classifier을 통해 topic_idx를 전부 분류\n","        self.classifier = tf.keras.layers.Dense(num_class,\n","                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range), \n","                                                name=\"classifier\") \n","\n","\n","    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False): \n","        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n","        pooled_output = outputs[1]\n","        pooled_output = self.dropout(pooled_output, training=training)\n","        logits = self.classifier(pooled_output)\n","\n","        return logits\n","\n","cls_model = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174,"referenced_widgets":["19b29fb0339e4187b36b8debd6604fcf","b1b2b417c9e34306b94a2597aff66939","3834361476824dc1a9b6826b9387ebeb","77023a8fb29448cd9814d9c145cfa7d6","daf3d4b29e0343159a26879e252ca148","c6ad64cee46f44f5bc923cff66bb0300","5cd16d8f02854419b5527b9dc9d40a9e","9b27d65a1115490cb8e5f229ba79c486","c3bfc9cf222d44409621b5ca6e6510db","727e0433a6a345b1a81568cff4f910c7","00462899e0b540d08a71fe46c8920318","f5645cb67055471294715a47ba80390e","572c46d818ae42f1805e2427ae501289","b47b6d5991774078b34477378f935823","3ffab7c2a2ff4d4b813507da0aca53db","2d321bb2b39c47b39c154c2836f331a4","1aa925d7709a48c58e4bc01cd0a48ea5","397244780fca4147ae13769a3dae7291","24aa2d307a33432282ca5d39397ea8bd","2b5b9dbb71ce44ce9059e5f698dd570e","9665bfe91cd44e66be3947c2dc5f5950","db93db3f8abb4097ba7c6d378eb33b61"]},"id":"c2F4tq4n0tyu","executionInfo":{"status":"ok","timestamp":1649669795017,"user_tz":-540,"elapsed":23055,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"8f31210a-7b77-418a-c17d-814ab50fc807"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/426 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19b29fb0339e4187b36b8debd6604fcf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/369M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5645cb67055471294715a47ba80390e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]}]},{"cell_type":"code","source":["# for i in range(5):\n","#     globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","#     optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","#     loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","#     metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","#     locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","#                                 loss=loss,\n","#                                 metrics=[metric])\n","    \n","#     es_callback = EarlyStopping(monitor='val_loss', \n","#                                 mode='min',\n","#                                 min_delta=0.0001, \n","#                                 patience=3,\n","#                                 baseline=0.4\n","#                                  ) \n","\n","#     DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","#     checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","#     checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","#     if os.path.exists(checkpoint_dir):\n","#         print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","#     else:\n","#         os.makedirs(checkpoint_dir, exist_ok=True)\n","#         print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","#     cp_callback = ModelCheckpoint(\n","#         checkpoint_path, \n","#         monitor='val_accuracy',\n","#         verbose=1, \n","#         save_best_only=True, \n","#         save_weights_only=True \n","#         )\n","    \n","#     history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","#                         validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","#                         epochs=NUM_EPOCHS,\n","#                         batch_size=BATCH_SIZE,\n","#                         callbacks=[es_callback, cp_callback]\n","#                         ) "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JD9HD3Uu00NA","outputId":"af0f01e8-8876-4401-ea6f-58eeb7e5a705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/stat/model -- Folder already exists \n","\n","Epoch 1/10\n","2571/9524 [=======>......................] - ETA: 1:31:48 - loss: 1.4117 - accuracy: 0.7256"]}]},{"cell_type":"code","source":["for i in range(5):\n","    if i == 0:\n","        globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","        locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","    \n","        es_callback = EarlyStopping(monitor='val_loss', \n","                                mode='min',\n","                                min_delta=0.0001, \n","                                patience=3,\n","                                baseline=0.4\n","                                 ) \n","\n","        DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","        checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","        checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","        if os.path.exists(checkpoint_dir):\n","            print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","        else:\n","            os.makedirs(checkpoint_dir, exist_ok=True)\n","            print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","        cp_callback = ModelCheckpoint(\n","            checkpoint_path, \n","            monitor='val_accuracy',\n","            verbose=1, \n","            save_best_only=True, \n","            save_weights_only=True \n","            )\n","    \n","        history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","                        validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        callbacks=[es_callback, cp_callback]\n","                        ) "],"metadata":{"id":"-gth-4Gi4RP9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649665114865,"user_tz":-540,"elapsed":28443117,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"b51c43cc-838d-4e13-d8e3-7f3ab948cae1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/stat/model -- Folder already exists \n","\n","Epoch 1/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.6409 - accuracy: 0.8590\n","Epoch 1: val_accuracy improved from -inf to 0.92240, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold0.ckpt\n","9524/9524 [==============================] - 4776s 498ms/step - loss: 0.6409 - accuracy: 0.8590 - val_loss: 0.2913 - val_accuracy: 0.9224\n","Epoch 2/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2598 - accuracy: 0.9295\n","Epoch 2: val_accuracy improved from 0.92240 to 0.92517, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold0.ckpt\n","9524/9524 [==============================] - 4747s 498ms/step - loss: 0.2598 - accuracy: 0.9295 - val_loss: 0.2793 - val_accuracy: 0.9252\n","Epoch 3/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2315 - accuracy: 0.9359\n","Epoch 3: val_accuracy improved from 0.92517 to 0.92598, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold0.ckpt\n","9524/9524 [==============================] - 4740s 498ms/step - loss: 0.2315 - accuracy: 0.9359 - val_loss: 0.2758 - val_accuracy: 0.9260\n","Epoch 4/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2098 - accuracy: 0.9412\n","Epoch 4: val_accuracy improved from 0.92598 to 0.92607, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold0.ckpt\n","9524/9524 [==============================] - 4735s 497ms/step - loss: 0.2098 - accuracy: 0.9412 - val_loss: 0.2799 - val_accuracy: 0.9261\n","Epoch 5/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9462\n","Epoch 5: val_accuracy improved from 0.92607 to 0.92643, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold0.ckpt\n","9524/9524 [==============================] - 4721s 496ms/step - loss: 0.1904 - accuracy: 0.9462 - val_loss: 0.2827 - val_accuracy: 0.9264\n","Epoch 6/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.1734 - accuracy: 0.9505\n","Epoch 6: val_accuracy did not improve from 0.92643\n","9524/9524 [==============================] - 4721s 496ms/step - loss: 0.1734 - accuracy: 0.9505 - val_loss: 0.2887 - val_accuracy: 0.9251\n"]}]},{"cell_type":"code","source":["for i in range(5):\n","    if i == 1:\n","        globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","        locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","    \n","        es_callback = EarlyStopping(monitor='val_loss', \n","                                mode='min',\n","                                min_delta=0.0001, \n","                                patience=3,\n","                                baseline=0.4\n","                                 ) \n","\n","        DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","        checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","        checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","        if os.path.exists(checkpoint_dir):\n","            print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","        else:\n","            os.makedirs(checkpoint_dir, exist_ok=True)\n","            print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","        cp_callback = ModelCheckpoint(\n","            checkpoint_path, \n","            monitor='val_accuracy',\n","            verbose=1, \n","            save_best_only=True, \n","            save_weights_only=True \n","            )\n","    \n","        history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","                        validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        callbacks=[es_callback, cp_callback]\n","                        ) "],"metadata":{"id":"5WRWCNxg4XLf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","    if i == 2:\n","        globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","        locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","    \n","        es_callback = EarlyStopping(monitor='val_loss', \n","                                mode='min',\n","                                min_delta=0.0001, \n","                                patience=3,\n","                                baseline=0.4\n","                                 ) \n","\n","        DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","        checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","        checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","        if os.path.exists(checkpoint_dir):\n","            print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","        else:\n","            os.makedirs(checkpoint_dir, exist_ok=True)\n","            print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","        cp_callback = ModelCheckpoint(\n","            checkpoint_path, \n","            monitor='val_accuracy',\n","            verbose=1, \n","            save_best_only=True, \n","            save_weights_only=True \n","            )\n","    \n","        history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","                        validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        callbacks=[es_callback, cp_callback]\n","                        ) "],"metadata":{"id":"i4E59FAb4Xrp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649698197648,"user_tz":-540,"elapsed":28402641,"user":{"displayName":"장준보","userId":"12796992458142872403"}},"outputId":"0397e849-52bc-4cd5-e6c1-d7e890917a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["All PyTorch model weights were used when initializing TFBertModel.\n","\n","All the weights of TFBertModel were initialized from the PyTorch model.\n","If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/stat/model -- Folder already exists \n","\n","Epoch 1/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.6429 - accuracy: 0.8585\n","Epoch 1: val_accuracy improved from -inf to 0.92296, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold2.ckpt\n","9524/9524 [==============================] - 4763s 497ms/step - loss: 0.6429 - accuracy: 0.8585 - val_loss: 0.2884 - val_accuracy: 0.9230\n","Epoch 2/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2602 - accuracy: 0.9293\n","Epoch 2: val_accuracy improved from 0.92296 to 0.92668, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold2.ckpt\n","9524/9524 [==============================] - 4726s 496ms/step - loss: 0.2602 - accuracy: 0.9293 - val_loss: 0.2752 - val_accuracy: 0.9267\n","Epoch 3/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2318 - accuracy: 0.9359\n","Epoch 3: val_accuracy improved from 0.92668 to 0.92731, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold2.ckpt\n","9524/9524 [==============================] - 4730s 497ms/step - loss: 0.2318 - accuracy: 0.9359 - val_loss: 0.2713 - val_accuracy: 0.9273\n","Epoch 4/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.2095 - accuracy: 0.9415\n","Epoch 4: val_accuracy improved from 0.92731 to 0.92732, saving model to /content/drive/MyDrive/stat/model/best_model3_84_fold2.ckpt\n","9524/9524 [==============================] - 4730s 497ms/step - loss: 0.2095 - accuracy: 0.9415 - val_loss: 0.2729 - val_accuracy: 0.9273\n","Epoch 5/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.1903 - accuracy: 0.9461\n","Epoch 5: val_accuracy did not improve from 0.92732\n","9524/9524 [==============================] - 4724s 496ms/step - loss: 0.1903 - accuracy: 0.9461 - val_loss: 0.2791 - val_accuracy: 0.9271\n","Epoch 6/10\n","9524/9524 [==============================] - ETA: 0s - loss: 0.1729 - accuracy: 0.9506\n","Epoch 6: val_accuracy did not improve from 0.92732\n","9524/9524 [==============================] - 4725s 496ms/step - loss: 0.1729 - accuracy: 0.9506 - val_loss: 0.2867 - val_accuracy: 0.9262\n"]}]},{"cell_type":"code","source":["for i in range(5):\n","    if i == 3:\n","        globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","        locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","    \n","        es_callback = EarlyStopping(monitor='val_loss', \n","                                mode='min',\n","                                min_delta=0.0001, \n","                                patience=3,\n","                                baseline=0.4\n","                                 ) \n","\n","        DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","        checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","        checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","        if os.path.exists(checkpoint_dir):\n","            print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","        else:\n","            os.makedirs(checkpoint_dir, exist_ok=True)\n","            print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","        cp_callback = ModelCheckpoint(\n","            checkpoint_path, \n","            monitor='val_accuracy',\n","            verbose=1, \n","            save_best_only=True, \n","            save_weights_only=True \n","            )\n","    \n","        history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","                        validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        callbacks=[es_callback, cp_callback]\n","                        ) "],"metadata":{"id":"oSfXQvO84YBP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","    if i == 4:\n","        globals()['cls_model_{}'.format(i)] = TFBertClassifier(model_name=model_name, dir_path='bert_ckpt',num_class=NUM_CLASS)\n","        optimizer = tfa.optimizers.RectifiedAdam(learning_rate=7.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-07, clipnorm=1.0)\n","        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","        metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n","\n","        locals()['cls_model_{}'.format(i)].compile(optimizer=optimizer,\n","                                loss=loss,\n","                                metrics=[metric])\n","    \n","        es_callback = EarlyStopping(monitor='val_loss', \n","                                mode='min',\n","                                min_delta=0.0001, \n","                                patience=3,\n","                                baseline=0.4\n","                                 ) \n","\n","        DATA_OUT_PATH = '/content/drive/MyDrive/stat/model/'\n","        checkpoint_path = DATA_OUT_PATH +  f'best_model3_84_fold{i}.ckpt'\n","        checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","        if os.path.exists(checkpoint_dir):\n","            print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n","        else:\n","            os.makedirs(checkpoint_dir, exist_ok=True)\n","            print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n","\n","  \n","        cp_callback = ModelCheckpoint(\n","            checkpoint_path, \n","            monitor='val_accuracy',\n","            verbose=1, \n","            save_best_only=True, \n","            save_weights_only=True \n","            )\n","    \n","        history = locals()['cls_model_{}'.format(i)].fit(locals()['train_news_inputs_{}'.format(i)], locals()['train_data_labels_{}'.format(i)], \n","                        validation_data=( locals()['valid_news_inputs_{}'.format(i)], locals()['valid_data_labels_{}'.format(i)]),\n","                        epochs=NUM_EPOCHS,\n","                        batch_size=BATCH_SIZE,\n","                        callbacks=[es_callback, cp_callback]\n","                        ) "],"metadata":{"id":"Mojx0MEU4b4W"},"execution_count":null,"outputs":[]}]}